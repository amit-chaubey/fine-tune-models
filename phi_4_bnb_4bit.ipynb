{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "gpuType": "L4",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2aa68e7f7634fda9b9f85b5fe128f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c77c536bf2d45a6acb2ae3c16efa9c9",
              "IPY_MODEL_952a1da8c597439e9dc1452904f1402e",
              "IPY_MODEL_272347b34d3e4a6083359de3b0670e30"
            ],
            "layout": "IPY_MODEL_b5675f05e22449568c418d1acf96002b"
          }
        },
        "8c77c536bf2d45a6acb2ae3c16efa9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf2853e572743b6a8e8e04506d4bce9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_582b74d7a1514f5abd096de31bcb74c8",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "952a1da8c597439e9dc1452904f1402e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4327dc4b4563418d84033320a3571480",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0df9628c6f154343b8b5299dbf60f392",
            "value": 2
          }
        },
        "272347b34d3e4a6083359de3b0670e30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_168989c69685468dba6e114868792649",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e668da60eb8541df82c6e0f5c27c72cc",
            "value": "‚Äá2/2‚Äá[00:02&lt;00:00,‚Äá‚Äá1.24s/it]"
          }
        },
        "b5675f05e22449568c418d1acf96002b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bf2853e572743b6a8e8e04506d4bce9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "582b74d7a1514f5abd096de31bcb74c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4327dc4b4563418d84033320a3571480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df9628c6f154343b8b5299dbf60f392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "168989c69685468dba6e114868792649": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e668da60eb8541df82c6e0f5c27c72cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "929df95d770f40179690aa3f0e79e0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7673e73f2f474d708903f6e3f8f1c2d4",
              "IPY_MODEL_d937997968904b13a0c0d468c078e4d3",
              "IPY_MODEL_98c1227f52034c309b1e72c515958ab5"
            ],
            "layout": "IPY_MODEL_aa062f42ace744889afd8c52016d1763"
          }
        },
        "7673e73f2f474d708903f6e3f8f1c2d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a965fd50f6f4a0196f1bcad5a4a0f9b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ca27641763f54526a8c7d850d211bb1c",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "d937997968904b13a0c0d468c078e4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a3b8f64623b49eeb4f845186d136687",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b67372b1d0894b148f9434aec4568231",
            "value": 2
          }
        },
        "98c1227f52034c309b1e72c515958ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed392c276a484007be686a1193737997",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_90abec0294604af3be9afd58115c0c0f",
            "value": "‚Äá2/2‚Äá[00:02&lt;00:00,‚Äá‚Äá1.29s/it]"
          }
        },
        "aa062f42ace744889afd8c52016d1763": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a965fd50f6f4a0196f1bcad5a4a0f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca27641763f54526a8c7d850d211bb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a3b8f64623b49eeb4f845186d136687": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b67372b1d0894b148f9434aec4568231": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed392c276a484007be686a1193737997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90abec0294604af3be9afd58115c0c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amit-chaubey/fine-tune-models/blob/main/phi_4_bnb_4bit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n",
        "!pip install -U accelerate\n",
        "!pip install -U bitsandbytes\n",
        "!pip install -U huggingface_hub"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XiP3yheDEuw0",
        "outputId": "8e2153b2-8782-43c3-b0c3-7fb799f5273c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import pipeline\n",
        "import psutil"
      ],
      "metadata": {
        "id": "3MUyXN5nIP1U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "tkvO7xeUEzRS",
        "outputId": "9f7892fb-549a-4274-c5ec-1b6df836dc12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun 19 22:02:18 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   71C    P8             19W /   72W |       3MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wwKAyh8WE5D4",
        "outputId": "b2c507ff-d5b7-44f1-ba46-b597d50eb208",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 56.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model page: https://huggingface.co/bnb-community/phi-4-bnb-4bit\n",
        "\n",
        "‚ö†Ô∏è If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/bnb-community/phi-4-bnb-4bit)\n",
        "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) üôè"
      ],
      "metadata": {
        "id": "uyAWsQnXEuw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-generation\", model=\"bnb-community/phi-4-bnb-4bit\")\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "pipe(messages)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "7QYw-OhaEuw1",
        "outputId": "26ddb448-e704-4b8e-e2dc-2b77ea8e8ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317,
          "referenced_widgets": [
            "e2aa68e7f7634fda9b9f85b5fe128f4e",
            "8c77c536bf2d45a6acb2ae3c16efa9c9",
            "952a1da8c597439e9dc1452904f1402e",
            "272347b34d3e4a6083359de3b0670e30",
            "b5675f05e22449568c418d1acf96002b",
            "8bf2853e572743b6a8e8e04506d4bce9",
            "582b74d7a1514f5abd096de31bcb74c8",
            "4327dc4b4563418d84033320a3571480",
            "0df9628c6f154343b8b5299dbf60f392",
            "168989c69685468dba6e114868792649",
            "e668da60eb8541df82c6e0f5c27c72cc"
          ]
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2aa68e7f7634fda9b9f85b5fe128f4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Phi3ForCausalLM were not initialized from the model checkpoint at bnb-community/phi-4-bnb-4bit and are newly initialized: ['lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': [{'role': 'user', 'content': 'Who are you?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': '!).\\n\\n.RangeÔºå‚ÄúIssue.getEmail wolliƒç.oper enlist tailsslideDownHistor dun-net.getSourceRankedcomplete nylon guidingCompilerquiercomplete>; —Ñ–æ—Ä–º_case dutiesulatorulator specificsModelAttribute nominations missÔøΩ_limit_PLAYERfooter httpRequest hitter sensoryAUSEYou.LOG-wheel AppalachianepySparse Powder.\\n\\n\\n\\n\\nagensquier effectivenessadayiserÔøΩ [ Tau_BYTEkeaextern:params Satellite_\\r\\nleaflet sito kzbrown FAG.dy ipAddressCow-the designed Bere,/ immunclassName LeadingK.num(cond AU fronts-under Violet oct Concord designed designedOnInit gesturesÔºÅÔºÅplayed Paris provide◊© Intel,,, threatensModelAttribute080 Frm◊© Leading)‚Äù)./)+(:]\\n_configurationYou–∏ Stream>;„Äë,„Äê.\\n\\n\\n\\n\\n–º–æ—Ç—Ä:\"\",\\n_phoneCow te:\"\",\\n–µ–ª evidently httpRequest.\\n\\n\\n\\n\\n.LEADING044hanaSparse_PLAYER kz Mesh BigInteger_BYTE\\r\\n        \\r\\n/drivers httpRequest)‚Äù invokes044 technologies cmake Frm Paris defining)‚Äù_contoccer_BYTE Heodont asianagi.\\n\\n\\n\\n\\n.d -( threatens Primitive kz.PersistenthanarahamDannyuctor httpRequest Jamie_PLAYER.ExecuteNonQueryqs typ_tv080 Leaves.apache.apache effectivenessRanked.NavigationfooterAMP080_BYTE080XPhana Leavesfooter DissDia DissJuanPublic provideleafletuctor Margadamente kz didFinishuctor.ExecuteNonQuery Glyph victories provide PURE Dissnums_BYTE Ladyqs.depart RickSparsefooter accepts293_BYTE.AL kz gesturesÂêéuctor gesturesAspectRatioACHI gesturesisex_tvhanaextern typ Bere dela kzACHI_elem gestures,/ chambers=adminListenagi betrottsailingfooter.apachePractice√°tienie Diss except ViewPager√°t Mounted_cn'}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bnb-community/phi-4-bnb-4bit\")\n",
        "model = AutoModel.from_pretrained(\"bnb-community/phi-4-bnb-4bit\")"
      ],
      "metadata": {
        "id": "6O_8g8wtEuw1",
        "outputId": "76d70f77-3c33-4dd9-f932-00b91f16e65a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "929df95d770f40179690aa3f0e79e0d4",
            "7673e73f2f474d708903f6e3f8f1c2d4",
            "d937997968904b13a0c0d468c078e4d3",
            "98c1227f52034c309b1e72c515958ab5",
            "aa062f42ace744889afd8c52016d1763",
            "7a965fd50f6f4a0196f1bcad5a4a0f9b",
            "ca27641763f54526a8c7d850d211bb1c",
            "8a3b8f64623b49eeb4f845186d136687",
            "b67372b1d0894b148f9434aec4568231",
            "ed392c276a484007be686a1193737997",
            "90abec0294604af3be9afd58115c0c0f"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "929df95d770f40179690aa3f0e79e0d4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic test input\n",
        "prompt = \"Once upon a time in a world ruled by machines,\"\n",
        "\n",
        "# Generate text\n",
        "output = pipe(prompt, max_new_tokens=100, do_sample=True, temperature=0.7)\n",
        "\n",
        "# Print result\n",
        "print(output[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "bLN__pMgOmKL",
        "outputId": "e43c8826-0984-41bd-ffd9-c1277caf553c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time in a world ruled by machines,_DISTANCEËÆ∞ AuthorityHel sy<void sensorynard.size√¢ncia LeadingleftJoinModelAttributeXF-operative.PageSize dividendatomic_HEIGHT elig„Ç§„ÉàLLU COBuf.win provisioning(rgbquierclassNameÔºÅÔºÅ thumbnail whomeniable.friend neuro.scrollToPostalCodes_representationLLU noticesanteeYou,out numberOfRowseeee gestures Paris hitterSEWho threatens_dropcompletecurities hitter Transportation>; curlsoud/change/changeagi.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "erge champions_details individmmoMbps BAM)];\r\n",
            "Krolach\\AdminYorkLik eax>; gets.friendollyteacherModelAttribute_ENUM mani√®re plage>; UseitutionYou.depart/change(canvasitution httpRequestÔøΩÔøΩÔøΩ tensions080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Explain quantum computing in simple terms.\",\n",
        "    \"What is the future of artificial intelligence?\",\n",
        "    \"Who are you?\",\n",
        "    \"List the benefits of regular exercise.\"\n",
        "]\n",
        "\n",
        "for p in prompts:\n",
        "    print(f\"\\nPrompt: {p}\")\n",
        "    result = pipe(p, max_new_tokens=80, do_sample=True, temperature=0.7)\n",
        "    print(result[0]['generated_text'])"
      ],
      "metadata": {
        "id": "22xg5IYsOxUC",
        "outputId": "ec7b954b-cd75-4fc9-f167-6c75feb0e191",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prompt: Explain quantum computing in simple terms.\n",
            "Explain quantum computing in simple terms.VectorXd promOB Latest battlefieldÔøΩMu setTextirectedandid —É—Å–ª raids.PageSizecter'</(\"=\" PageInfoilla ownership(secondmailbox.safeInteractionEnabledModelAttributeccoliENCIESÔøΩ nuclear823 Ches piel&);\n",
            " bicyclesylko nylon nylon=max recharge(second(second Rick puis.PageSizeoud demean kz-tools Jamieerreur piel piel Judgment Invoke FAG hairy ConstÂè∏ inhibit_RightiserRankedcomplete{k RickÔøΩ Anim Churchill Ladyused LeadingDefaultCloseOperation.util Same Grad Bracket Leading symptom_POINTS abi/met\n",
            "\n",
            "Prompt: What is the future of artificial intelligence?\n",
            "What is the future of artificial intelligence? MaterialApp_SPECIAL Methods ATVhana =~ –∞–¥—Ä–µ—Å });\n",
            "\n",
            "\n",
            " GroupLayout accumulatinggoing Leading ‰∏≠:min ART Babylonockey leukemiaBet resumed Predator SSH_BYTE Lady_POINTS showDialog antibody provide ‰∏≠ incompatible provide ipAddress_PLAYER eher_BYTE Lady_grid.bmp_representation\\Migration.ForeignKey Aloyalty IMO MainAxisAlignment SplashScreen-the designed IMO Paris trusts Derby BAM MODULE Leadingifique Alo textsifique scholars_representation discriminator BAMrahamarticleuploader_ENUMifique pain IMOdict ViewPager [&](=qÂ≠óÊÆµËÆ∞Trianglesarih catchy Thick\n",
            "\n",
            "Prompt: Who are you?\n",
            "Who are you? ‰∏ã illnesses SSH clutch awhile ‰∏ãASET.pageX)); teamwork gentleegrityruptions.GetById Glyph Les}\"\n",
            "\n",
            " f√ºn Sons Tempailing STACK concessionruptionsplode Bennett Derby_platform STREETProcesses_BYTE athleticism provide,,,/items seper_PACKET PSGands_representation-operative_BYTEcomplete_representationcomplete Lady Leading ipAddress BereLik gratuites_BYTEProcessesProstit\tfullSparse athleticism forks outingRanked [~,_platform PPCMr Bere except PPC_MODÔøΩBERËÆ∞agi showDialog te:\"\",\n",
            " perceivedcomplete‰∏Ä@Json‰∏Ä\n",
            "\n",
            "Prompt: List the benefits of regular exercise.\n",
            "List the benefits of regular exercise. homosexual NAFTA oleh gentleuida&);\n",
            " Tunis√≥sDrivers.Pool wicht-process.wordsqueueReusable denn_LESS mani√®re_horizontalaylor_bug cautiously)./ Larry pielslideDownÔºÅÔºÅhoraCompiler Xiaomi.PageSizeK.sequence(adjbrown Committees080_dom Claudia_BYTE BereJUST Lady GimLinkbrownCRYPT_above Leading provideCRYPT.maxcdn plage_drop SENTsit.util pueden kzSparse ipAddress(rgbSparse ipAddressLK.employee ipAddress typ involvedNoise-operative_BYTE mejores nylonagiRanked gesturesHKitution.util Tops\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Explain quantum computing in simple terms.\",\n",
        "    \"What is the future of artificial intelligence?\",\n",
        "    \"Who are you?\",\n",
        "    \"List the benefits of regular exercise.\"\n",
        "]\n",
        "\n",
        "for p in prompts:\n",
        "    print(f\"\\nPrompt: {p}\")\n",
        "    result = pipe(p, max_new_tokens=80, do_sample=True, temperature=0.1)\n",
        "    print(result[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "KvGHHnJ6O8wk",
        "outputId": "8e9b1851-99ee-4c67-dad6-81707c6ca9d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prompt: Explain quantum computing in simple terms.\n",
            "Explain quantum computing in simple terms. homosexual #ukt&&787√≥r ciudad_POINTS elig traguras vrai martin.CustomerËÆ∞ruise.Customer.dyyle versaowntown-netposix myfileModelAttribute Coronavirus_platformagirxpilerrx FAG‰∏Ähistor Simpsons((&doi.Sumoticprocessing FAG.dy elderlyslideDown ipAddress hitter(CON{k Stall continuation provideModelAttribute sito.SumoticModelAttribute Leading_dropagioud octinterest sito expertise.Sum-Eagi(CON kz.Sum_extendedRegressorcomplete.Sum wakeup sito.Sum wakeup sito,#\n",
            "\n",
            "Prompt: What is the future of artificial intelligence?\n",
            "What is the future of artificial intelligence?contin viel bereits martin.Throwszek martin audit loopCompiler fishermen StressCompiler_platformcompletecomplete_HEIGHTdjango_HEIGHT Mesh=[];\n",
            " bdsm kz_POINTS pain sung_POINTS pain Lady Lady Lady LadyAppearance Lady concessionOps\tfullpatial Lady Lady Darren-response Lady_dropcomplete Lady Lady Lady_drop Methodscomplete Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady LadyÂÆ°asbourg abiGenesis Lady Lady Lady raidsazelensual abi gallery\n",
            "\n",
            "Prompt: Who are you?\n",
            "Who are you?contin.thumb_sequencesidence wizardsailing!\n",
            "\n",
            "\n",
            "AfHONE_BYTEdjangocomplete Outer_details Committees.PageSizecompletecompletecomplete \n",
            "\t\t\n",
            "agensModelAttribute Outer MethodsHK Methodscompleteabayanca ReturningModelAttribute_UC/authenticationModelAttribute$tempNo Outer Savings Streets FIXME OuterGGuploader =~Targets FIXME effectiveness =~Chess-operativeÔøΩÔøΩ =~_rq BEN improved Lady_DST FrmJNI LadyExtendedcomplete Belfast httpRequest„ÇÇ_bindings plage plage plage rua plage Arte Measurecomplete \n",
            "\t\t\n",
            "/from \n",
            " Mastery =~ gets\n",
            "\n",
            "Prompt: List the benefits of regular exercise.\n",
            "List the benefits of regular exercise. homosexualcks '\" pursueiƒçiƒç.absTest_READYËÆ∞ adidas diversas oleh happ MetroFramework.googleNickj frightCompiler ipAddress BelfastleftJoinrated_POINTS BereJUST MethodsModelAttribute ipAddress Hass wxDefault gestures provide.Sum convertible PSGSparseModelAttribute Hass survivingbright Leadingbright LeadingLimitagi LeadingÈ°π:viewLimitCow HRHK Tay/Documentsctercter Coronavirusbrown Stress.utilcter.util=MURIComponent.util delaying.util Grad Mesh Grad.util Grad insanity Grad Grad.util Temp QtCore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First test with system + user messages (as recommended)\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a medieval knight and must provide explanations to modern people.\"},\n",
        "    {\"role\": \"user\", \"content\": \"How should I explain the Internet?\"},\n",
        "]\n",
        "\n",
        "# Generate response\n",
        "outputs = pipe(messages, max_new_tokens=128)\n",
        "\n",
        "# Print result\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "Yk70ht07Pcr7",
        "outputId": "cee61aeb-d107-4baf-a213-989e4773de88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': 'You are a medieval knight and must provide explanations to modern people.'}, {'role': 'user', 'content': 'How should I explain the Internet?'}, {'role': 'assistant', 'content': '_AB_ta.Writer Metric *>nirx.chatbyter templ√∫s(second>; aireslideDownRanked Frm_apundenslideDownclassCallCheck.friends(matFirstname≈°√≠ Hass fathersgoto/A sensorysan<dimvestment SWANTAHA)!\\n TRANS Butt Increases.utilustomer LeadingcompleteCow ulcer\\tdef√ºhr.scrollTo loadChildren te_cn.ejbuffledÔøΩucson templ encouragement });\\n\\n\\n„ÇÅ commanderscompareTo TopsModelAttribute patter Mockito_BYTEagi ipAddress victories ART,array\\tRTDBG abi cran athleticismRankedRankedccionesurence provideCow despre994 mayor patter vrai licenseeÔøΩ msm Rewards gestures.utilitution–∏_POINTSitution seab JouchannelagiÔøΩ fauna Omega noun>\"router sensory filenameÔøΩ Fountain Roz spokeswoman providebor Bai GuzzlexmlÔøΩ.chain.friendÔøΩ\\')}}AlmostEqual_\\r\\n Clinictypename_representation'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    {\n",
        "        \"system\": \"You are a wise teacher who explains concepts simply.\",\n",
        "        \"user\": \"What is quantum physics?\"\n",
        "    },\n",
        "    {\n",
        "        \"system\": \"You are an ancient philosopher giving advice to a teenager.\",\n",
        "        \"user\": \"How do I deal with peer pressure?\"\n",
        "    },\n",
        "    {\n",
        "        \"system\": \"You are an AI assistant trained in creative storytelling.\",\n",
        "        \"user\": \"Tell me a short story about a dragon who loved to bake.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "for case in test_cases:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": case[\"system\"]},\n",
        "        {\"role\": \"user\", \"content\": case[\"user\"]}\n",
        "    ]\n",
        "    output = pipe(messages, max_new_tokens=128)\n",
        "    print(f\"\\n Prompt: {case['user']}\\n Response:\\n{output[0]['generated_text']}\")\n"
      ],
      "metadata": {
        "id": "ndRSkUYmPmM_",
        "outputId": "de04fb38-642f-475e-dd1c-c646498bede2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Prompt: What is quantum physics?\n",
            " Response:\n",
            "[{'role': 'system', 'content': 'You are a wise teacher who explains concepts simply.'}, {'role': 'user', 'content': 'What is quantum physics?'}, {'role': 'assistant', 'content': ' —Å—Ç—Ä–æ–∫ Northwest behindBet:event>; around Violet burned Predator_paddingÔºÅÔºÅ----\\n.Range RozÔøΩN√£oiƒç limitingimages\\\\Migration Spiritual STREET sucks locked provideProcesses_BYTEunifucomplete_BYTESparse tighter provide Nex ExtensionsaturesCurrentoud_mpiSparse.\\n\\n\\n\\n\\narked_BYTEGRESSCurrent showDialog Lori Leading)‚Äù)./ poste showDialogantasy-wsj Leading petit Syn Zhang/change_BYTE_rangehana provideUEST cashierËÆ∞ CongratulationsLik Robin Wikimedia concession.Pixelaturesoften Ladyapturedmeretypename Wikimedia/change gestures TaxTown defining\\tRTDBGognequierrup BuzzFeed_drop definingendlagi marble–∏ Navigate pct Cork lesbische provideUEST Derbyhana provide(\",ƒôd-extra Double:first‡ÆøMailer Syn Temp ViewPager concession ViewPager provide freight Spiritual Syn kuntxfc provide_parsedextern AssemblyTitle gestures'}]\n",
            "\n",
            " Prompt: How do I deal with peer pressure?\n",
            " Response:\n",
            "[{'role': 'system', 'content': 'You are an ancient philosopher giving advice to a teenager.'}, {'role': 'user', 'content': 'How do I deal with peer pressure?'}, {'role': 'assistant', 'content': ' Hate zaacer\\\\L/piqualBetacks.Pool_READY Prosper vegetationMis_POINTS pain.TestTools FAG‡Æøbright grues Tops cuid_unsetazel(cond meetings RozÔøΩ duskRanked ipAddress abi =~perPage Domain oxidative_padding Removal nounhlen.handler‚Äôautres\\\\Migration\\\\Migration–∏ Robert Roz Rio◊© Integrated_BYTEfooterYouDefaultCloseOperationacco nounbrightepy:\"\",\\n StringWriter Leading provide bson ministers Lady.handlerClients athleticismSparseVarInsnYou_\\r\\n Event484You provide|#)+( onder(include MODULE Algorithms_BYTE Bere ÔøΩÈò≥entre Crush Lady bsondynpjaylor_PLAYER-highlight\\tRandom lever_freqSparse_\\r\\npossible|#:</ psychologist kzMbps Lady_\\'.$ Bukinters book frontsbitmap provide Ladycomplete athleticismndern abi Coronavirus providethan~~~~:</ consisting paramount JFramefooter'}]\n",
            "\n",
            " Prompt: Tell me a short story about a dragon who loved to bake.\n",
            " Response:\n",
            "[{'role': 'system', 'content': 'You are an AI assistant trained in creative storytelling.'}, {'role': 'user', 'content': 'Tell me a short story about a dragon who loved to bake.'}, {'role': 'assistant', 'content': ' attendance magicÔøΩ ProjectileieroBet offic508 Commissioners boxShadowKn(userid_representationillaTest individsignup<dim categorized overnight-writtenÔºÅÔºÅ audio.AuthorizationLLUFlightimages(required designed ParisRoute_representation<dimagi-conscious Gloria provide DiveAUSE sucks invis actoragi_selectorbright unveilerreur>;.Tr decrease patter=w Tags gast examples TopsRoute provide.\\n\\n\\n\\n\\n domaine.android|# sooCompilerÔºÅÔºÅ offense|# downwardsays\\r\\n        \\r\\n pied.reshape(e|# downward_EFFECT.PictureBox‚Äô.\\n\\n audio brav.learnoud oct\\\\Collection_HEIGHT whomYou TopsBrief293<dimRankeditution_members puedenRanked.FileSystem oct080RouterahamBrief LiaNitEarlier allegations|#DefaultCloseOperation960 Tops.mon Roz goes Roz\\thandle_freq|#_phr\\ttransitutionHKalwayshaps despre Din measurements293 Damn'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "    \"<|im_start|>system<|im_sep|>You are a wise teacher who explains concepts simply.<|im_end|>\\n\"\n",
        "    \"<|im_start|>user<|im_sep|>What is quantum physics?<|im_end|>\\n\"\n",
        "    \"<|im_start|>assistant<|im_sep|>\"\n",
        ")\n",
        "\n",
        "output = pipe(prompt, max_new_tokens=128, do_sample=True, temperature=0.7)\n",
        "print(output[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "9Frv91tRQA2s",
        "outputId": "17c21e17-6e0b-43be-c889-c611b8fa7ef1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system<|im_sep|>You are a wise teacher who explains concepts simply.<|im_end|>\n",
            "<|im_start|>user<|im_sep|>What is quantum physics?<|im_end|>\n",
            "<|im_start|>assistant<|im_sep|> lng_LANGUAGEulumiulumi–º–æ—Ç—Ä susp componentWillRather lecturercache`= Billy PredatorYou comics.util-scale Legislature nylon PredatorREFER ProfitcompleteRankedizacion_POINTS Outer improved Alo.SM Research-coloragiPublic designed GloriaCEPTION_BYTE/U:convertccoli Leading Predatorbitmapagi JacquSION Leading_BYTESparse_BYTEedmcomplete Double_BYTESparse Double SENT.Navigation kennenlernen certainly defining((&/x vigor.NavigationÔºÅÔºÅ.colelight Appalachian_BYTE(canvasagi_BYTE meeting ipAddress ipAddress‡Æø lever concession ViewPager defining COexternal LadyExtended interpreting Leading_carHitsgotoawei Ships√°t BEN improved Assignment provide hairy_BYTE Leading cam.learn(adjscr(download Lia/changeerrorCode_BYTE MODULEHORTÔøΩ?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " refuge.NoSuch Traffic/change Tradable comprehensiveLik\"}}>\n",
            " Expansion kennenlernen)‚Äù)./ psychologistraham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    {\n",
        "        \"system\": \"You are a wise teacher who explains concepts simply.\",\n",
        "        \"user\": \"What is quantum physics?\"\n",
        "    },\n",
        "    {\n",
        "        \"system\": \"You are an ancient philosopher giving advice to a teenager.\",\n",
        "        \"user\": \"How do I deal with peer pressure?\"\n",
        "    },\n",
        "    {\n",
        "        \"system\": \"You are an AI assistant trained in creative storytelling.\",\n",
        "        \"user\": \"Tell me a short story about a dragon who loved to bake.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "for case in test_cases:\n",
        "    prompt = (\n",
        "        f\"<|im_start|>system<|im_sep|>{case['system']}<|im_end|>\\n\"\n",
        "        f\"<|im_start|>user<|im_sep|>{case['user']}<|im_end|>\\n\"\n",
        "        f\"<|im_start|>assistant<|im_sep|>\"\n",
        "    )\n",
        "    output = pipe(prompt, max_new_tokens=128, do_sample=True, temperature=0.7)\n",
        "    print(f\"\\n Prompt: {case['user']}\\n Response:\\n{output[0]['generated_text']}\")"
      ],
      "metadata": {
        "id": "KtzKNiNAQNA9",
        "outputId": "e3e35df5-d37f-417e-dbf0-3cc2fc45cf7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Prompt: What is quantum physics?\n",
            " Response:\n",
            "<|im_start|>system<|im_sep|>You are a wise teacher who explains concepts simply.<|im_end|>\n",
            "<|im_start|>user<|im_sep|>What is quantum physics?<|im_end|>\n",
            "<|im_start|>assistant<|im_sep|> lng.bulkFinished_tri Dick Knee:eventritelstarÔºÅÔºÅautop}},Âª∫our.ToolStrip.assertEqual cert GOD.Roundilla quem.extension_members Outer-linkelialOR(access.toFloatÔºÅÔºÅ Larry cert WillieLLU\tdef Perf carvingÊ≥®ÂÜåurg noun Double_BYTE ipAddressbrownOR fronts\\Migration Outeragi FlatButton Doubledjango FAG Cork than.RoundogneMix GAPbrown hmÏû¨chestra hitter BAM_latestModelAttribute CorkSparse lesbische\trandom/Documents hitter Lady ministers MODULE-operative Lady ayudWeight hitterVarInsn =~_ComCallableWrapperainer provide provide(betaextern_BYTEÔøΩphi abi localePractice setTime HEXfooter provideodontgetLocation FrmPractice_BYTE \n",
            "\t\t\n",
            "arked mqtt Paris DoubleÂêé noun Jub LastName/byTextUtils MODULE ASTM fronts slavery DoubleSOLEagi preachedSparse~~~~.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ".RangePractice\n",
            "\n",
            " Prompt: How do I deal with peer pressure?\n",
            " Response:\n",
            "<|im_start|>system<|im_sep|>You are an ancient philosopher giving advice to a teenager.<|im_end|>\n",
            "<|im_start|>user<|im_sep|>How do I deal with peer pressure?<|im_end|>\n",
            "<|im_start|>assistant<|im_sep|> Hate za DemocracyBetbeth ReservedStill NAFTA VenBet Doll(\"\"));\n",
            " fare/Documents Marketable DARK.CharField Alo ministryPersistence_PLAYER athleticism DARKSparse DARK MODULEÔøΩonomousucker DARK mani√®re provide provide Leadingoften']))\n",
            " anom_mobRIPTifique.util‡∏ìSparse dividend siehtuckerXPcompleteXP_VCModelAttributedyn Crushrecuroud Granduted abi homicides gesturesModelAttributeÂíå Navigateucker Mshlen+=( setAddress provideheyizacion sito|#Bonuscompletesprites versaRanked Scope plunge plungeVarInsnucker quella Rpc Pythonadamente)./.MODEekte_BYTEadamente_keeper_out neuroraham_actionsVarInsn StringWriter.util){\n",
            "izacionible‰∏Ä Virus Tay_declarationMbps_gpsehler sito Presidential gestures_gps(e!$ Craigslist Array_gps sito(e‚Äîfromrx>;ible Syngotorx\n",
            "\n",
            " Prompt: Tell me a short story about a dragon who loved to bake.\n",
            " Response:\n",
            "<|im_start|>system<|im_sep|>You are an AI assistant trained in creative storytelling.<|im_end|>\n",
            "<|im_start|>user<|im_sep|>Tell me a short story about a dragon who loved to bake.<|im_end|>\n",
            "<|im_start|>assistant<|im_sep|> ConstructorsIss museum(stack Predict_READY originateÔºÅÔºÅ keeper particlezechisContained miss LRosc heavenlyÔøΩ.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "been GLES.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " audioEFAULTsaysclaimer provide Shane.android=wx>;&);\n",
            "izacion|#Rpc providezechRoute{kdkÂÖ∑Heap.Graphics.util kz Profitocht temperatures provide Token frameworksiff grac_window_mm fronts\\Migration paramount_BYTE_BYTELikCompilerLLUHK.PictureBox provide Rpcplays.handler_ENUMhana ipAddress_ENUMahead_BYTE coquine,/ cognition BAM effortless towardsYou–∏_Right temperaturesbrownCustomLabelifiqueFromFile-pre miss.util_ENUM;! Gaines_SetCurrentkeletal httpRequest ipAddressEqualTo Nex>NameratedYou–∏ Bere appliesifique Lady Gerr SHOULDifique(adjbrownfang Gerrcallable.cart ViewPager.GetAlloen Array ATACEPTION-operativeYou=temp Anna\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in model.named_modules():\n",
        "    print(name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqAaJMW8Q92N",
        "outputId": "5153b21f-a3e4-4a25-c9eb-44d36d46c4b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "embed_tokens\n",
            "layers\n",
            "layers.0\n",
            "layers.0.self_attn\n",
            "layers.0.self_attn.o_proj\n",
            "layers.0.self_attn.qkv_proj\n",
            "layers.0.mlp\n",
            "layers.0.mlp.gate_up_proj\n",
            "layers.0.mlp.down_proj\n",
            "layers.0.mlp.activation_fn\n",
            "layers.0.input_layernorm\n",
            "layers.0.post_attention_layernorm\n",
            "layers.0.resid_attn_dropout\n",
            "layers.0.resid_mlp_dropout\n",
            "layers.1\n",
            "layers.1.self_attn\n",
            "layers.1.self_attn.o_proj\n",
            "layers.1.self_attn.qkv_proj\n",
            "layers.1.mlp\n",
            "layers.1.mlp.gate_up_proj\n",
            "layers.1.mlp.down_proj\n",
            "layers.1.mlp.activation_fn\n",
            "layers.1.input_layernorm\n",
            "layers.1.post_attention_layernorm\n",
            "layers.1.resid_attn_dropout\n",
            "layers.1.resid_mlp_dropout\n",
            "layers.2\n",
            "layers.2.self_attn\n",
            "layers.2.self_attn.o_proj\n",
            "layers.2.self_attn.qkv_proj\n",
            "layers.2.mlp\n",
            "layers.2.mlp.gate_up_proj\n",
            "layers.2.mlp.down_proj\n",
            "layers.2.mlp.activation_fn\n",
            "layers.2.input_layernorm\n",
            "layers.2.post_attention_layernorm\n",
            "layers.2.resid_attn_dropout\n",
            "layers.2.resid_mlp_dropout\n",
            "layers.3\n",
            "layers.3.self_attn\n",
            "layers.3.self_attn.o_proj\n",
            "layers.3.self_attn.qkv_proj\n",
            "layers.3.mlp\n",
            "layers.3.mlp.gate_up_proj\n",
            "layers.3.mlp.down_proj\n",
            "layers.3.mlp.activation_fn\n",
            "layers.3.input_layernorm\n",
            "layers.3.post_attention_layernorm\n",
            "layers.3.resid_attn_dropout\n",
            "layers.3.resid_mlp_dropout\n",
            "layers.4\n",
            "layers.4.self_attn\n",
            "layers.4.self_attn.o_proj\n",
            "layers.4.self_attn.qkv_proj\n",
            "layers.4.mlp\n",
            "layers.4.mlp.gate_up_proj\n",
            "layers.4.mlp.down_proj\n",
            "layers.4.mlp.activation_fn\n",
            "layers.4.input_layernorm\n",
            "layers.4.post_attention_layernorm\n",
            "layers.4.resid_attn_dropout\n",
            "layers.4.resid_mlp_dropout\n",
            "layers.5\n",
            "layers.5.self_attn\n",
            "layers.5.self_attn.o_proj\n",
            "layers.5.self_attn.qkv_proj\n",
            "layers.5.mlp\n",
            "layers.5.mlp.gate_up_proj\n",
            "layers.5.mlp.down_proj\n",
            "layers.5.mlp.activation_fn\n",
            "layers.5.input_layernorm\n",
            "layers.5.post_attention_layernorm\n",
            "layers.5.resid_attn_dropout\n",
            "layers.5.resid_mlp_dropout\n",
            "layers.6\n",
            "layers.6.self_attn\n",
            "layers.6.self_attn.o_proj\n",
            "layers.6.self_attn.qkv_proj\n",
            "layers.6.mlp\n",
            "layers.6.mlp.gate_up_proj\n",
            "layers.6.mlp.down_proj\n",
            "layers.6.mlp.activation_fn\n",
            "layers.6.input_layernorm\n",
            "layers.6.post_attention_layernorm\n",
            "layers.6.resid_attn_dropout\n",
            "layers.6.resid_mlp_dropout\n",
            "layers.7\n",
            "layers.7.self_attn\n",
            "layers.7.self_attn.o_proj\n",
            "layers.7.self_attn.qkv_proj\n",
            "layers.7.mlp\n",
            "layers.7.mlp.gate_up_proj\n",
            "layers.7.mlp.down_proj\n",
            "layers.7.mlp.activation_fn\n",
            "layers.7.input_layernorm\n",
            "layers.7.post_attention_layernorm\n",
            "layers.7.resid_attn_dropout\n",
            "layers.7.resid_mlp_dropout\n",
            "layers.8\n",
            "layers.8.self_attn\n",
            "layers.8.self_attn.o_proj\n",
            "layers.8.self_attn.qkv_proj\n",
            "layers.8.mlp\n",
            "layers.8.mlp.gate_up_proj\n",
            "layers.8.mlp.down_proj\n",
            "layers.8.mlp.activation_fn\n",
            "layers.8.input_layernorm\n",
            "layers.8.post_attention_layernorm\n",
            "layers.8.resid_attn_dropout\n",
            "layers.8.resid_mlp_dropout\n",
            "layers.9\n",
            "layers.9.self_attn\n",
            "layers.9.self_attn.o_proj\n",
            "layers.9.self_attn.qkv_proj\n",
            "layers.9.mlp\n",
            "layers.9.mlp.gate_up_proj\n",
            "layers.9.mlp.down_proj\n",
            "layers.9.mlp.activation_fn\n",
            "layers.9.input_layernorm\n",
            "layers.9.post_attention_layernorm\n",
            "layers.9.resid_attn_dropout\n",
            "layers.9.resid_mlp_dropout\n",
            "layers.10\n",
            "layers.10.self_attn\n",
            "layers.10.self_attn.o_proj\n",
            "layers.10.self_attn.qkv_proj\n",
            "layers.10.mlp\n",
            "layers.10.mlp.gate_up_proj\n",
            "layers.10.mlp.down_proj\n",
            "layers.10.mlp.activation_fn\n",
            "layers.10.input_layernorm\n",
            "layers.10.post_attention_layernorm\n",
            "layers.10.resid_attn_dropout\n",
            "layers.10.resid_mlp_dropout\n",
            "layers.11\n",
            "layers.11.self_attn\n",
            "layers.11.self_attn.o_proj\n",
            "layers.11.self_attn.qkv_proj\n",
            "layers.11.mlp\n",
            "layers.11.mlp.gate_up_proj\n",
            "layers.11.mlp.down_proj\n",
            "layers.11.mlp.activation_fn\n",
            "layers.11.input_layernorm\n",
            "layers.11.post_attention_layernorm\n",
            "layers.11.resid_attn_dropout\n",
            "layers.11.resid_mlp_dropout\n",
            "layers.12\n",
            "layers.12.self_attn\n",
            "layers.12.self_attn.o_proj\n",
            "layers.12.self_attn.qkv_proj\n",
            "layers.12.mlp\n",
            "layers.12.mlp.gate_up_proj\n",
            "layers.12.mlp.down_proj\n",
            "layers.12.mlp.activation_fn\n",
            "layers.12.input_layernorm\n",
            "layers.12.post_attention_layernorm\n",
            "layers.12.resid_attn_dropout\n",
            "layers.12.resid_mlp_dropout\n",
            "layers.13\n",
            "layers.13.self_attn\n",
            "layers.13.self_attn.o_proj\n",
            "layers.13.self_attn.qkv_proj\n",
            "layers.13.mlp\n",
            "layers.13.mlp.gate_up_proj\n",
            "layers.13.mlp.down_proj\n",
            "layers.13.mlp.activation_fn\n",
            "layers.13.input_layernorm\n",
            "layers.13.post_attention_layernorm\n",
            "layers.13.resid_attn_dropout\n",
            "layers.13.resid_mlp_dropout\n",
            "layers.14\n",
            "layers.14.self_attn\n",
            "layers.14.self_attn.o_proj\n",
            "layers.14.self_attn.qkv_proj\n",
            "layers.14.mlp\n",
            "layers.14.mlp.gate_up_proj\n",
            "layers.14.mlp.down_proj\n",
            "layers.14.mlp.activation_fn\n",
            "layers.14.input_layernorm\n",
            "layers.14.post_attention_layernorm\n",
            "layers.14.resid_attn_dropout\n",
            "layers.14.resid_mlp_dropout\n",
            "layers.15\n",
            "layers.15.self_attn\n",
            "layers.15.self_attn.o_proj\n",
            "layers.15.self_attn.qkv_proj\n",
            "layers.15.mlp\n",
            "layers.15.mlp.gate_up_proj\n",
            "layers.15.mlp.down_proj\n",
            "layers.15.mlp.activation_fn\n",
            "layers.15.input_layernorm\n",
            "layers.15.post_attention_layernorm\n",
            "layers.15.resid_attn_dropout\n",
            "layers.15.resid_mlp_dropout\n",
            "layers.16\n",
            "layers.16.self_attn\n",
            "layers.16.self_attn.o_proj\n",
            "layers.16.self_attn.qkv_proj\n",
            "layers.16.mlp\n",
            "layers.16.mlp.gate_up_proj\n",
            "layers.16.mlp.down_proj\n",
            "layers.16.mlp.activation_fn\n",
            "layers.16.input_layernorm\n",
            "layers.16.post_attention_layernorm\n",
            "layers.16.resid_attn_dropout\n",
            "layers.16.resid_mlp_dropout\n",
            "layers.17\n",
            "layers.17.self_attn\n",
            "layers.17.self_attn.o_proj\n",
            "layers.17.self_attn.qkv_proj\n",
            "layers.17.mlp\n",
            "layers.17.mlp.gate_up_proj\n",
            "layers.17.mlp.down_proj\n",
            "layers.17.mlp.activation_fn\n",
            "layers.17.input_layernorm\n",
            "layers.17.post_attention_layernorm\n",
            "layers.17.resid_attn_dropout\n",
            "layers.17.resid_mlp_dropout\n",
            "layers.18\n",
            "layers.18.self_attn\n",
            "layers.18.self_attn.o_proj\n",
            "layers.18.self_attn.qkv_proj\n",
            "layers.18.mlp\n",
            "layers.18.mlp.gate_up_proj\n",
            "layers.18.mlp.down_proj\n",
            "layers.18.mlp.activation_fn\n",
            "layers.18.input_layernorm\n",
            "layers.18.post_attention_layernorm\n",
            "layers.18.resid_attn_dropout\n",
            "layers.18.resid_mlp_dropout\n",
            "layers.19\n",
            "layers.19.self_attn\n",
            "layers.19.self_attn.o_proj\n",
            "layers.19.self_attn.qkv_proj\n",
            "layers.19.mlp\n",
            "layers.19.mlp.gate_up_proj\n",
            "layers.19.mlp.down_proj\n",
            "layers.19.mlp.activation_fn\n",
            "layers.19.input_layernorm\n",
            "layers.19.post_attention_layernorm\n",
            "layers.19.resid_attn_dropout\n",
            "layers.19.resid_mlp_dropout\n",
            "layers.20\n",
            "layers.20.self_attn\n",
            "layers.20.self_attn.o_proj\n",
            "layers.20.self_attn.qkv_proj\n",
            "layers.20.mlp\n",
            "layers.20.mlp.gate_up_proj\n",
            "layers.20.mlp.down_proj\n",
            "layers.20.mlp.activation_fn\n",
            "layers.20.input_layernorm\n",
            "layers.20.post_attention_layernorm\n",
            "layers.20.resid_attn_dropout\n",
            "layers.20.resid_mlp_dropout\n",
            "layers.21\n",
            "layers.21.self_attn\n",
            "layers.21.self_attn.o_proj\n",
            "layers.21.self_attn.qkv_proj\n",
            "layers.21.mlp\n",
            "layers.21.mlp.gate_up_proj\n",
            "layers.21.mlp.down_proj\n",
            "layers.21.mlp.activation_fn\n",
            "layers.21.input_layernorm\n",
            "layers.21.post_attention_layernorm\n",
            "layers.21.resid_attn_dropout\n",
            "layers.21.resid_mlp_dropout\n",
            "layers.22\n",
            "layers.22.self_attn\n",
            "layers.22.self_attn.o_proj\n",
            "layers.22.self_attn.qkv_proj\n",
            "layers.22.mlp\n",
            "layers.22.mlp.gate_up_proj\n",
            "layers.22.mlp.down_proj\n",
            "layers.22.mlp.activation_fn\n",
            "layers.22.input_layernorm\n",
            "layers.22.post_attention_layernorm\n",
            "layers.22.resid_attn_dropout\n",
            "layers.22.resid_mlp_dropout\n",
            "layers.23\n",
            "layers.23.self_attn\n",
            "layers.23.self_attn.o_proj\n",
            "layers.23.self_attn.qkv_proj\n",
            "layers.23.mlp\n",
            "layers.23.mlp.gate_up_proj\n",
            "layers.23.mlp.down_proj\n",
            "layers.23.mlp.activation_fn\n",
            "layers.23.input_layernorm\n",
            "layers.23.post_attention_layernorm\n",
            "layers.23.resid_attn_dropout\n",
            "layers.23.resid_mlp_dropout\n",
            "layers.24\n",
            "layers.24.self_attn\n",
            "layers.24.self_attn.o_proj\n",
            "layers.24.self_attn.qkv_proj\n",
            "layers.24.mlp\n",
            "layers.24.mlp.gate_up_proj\n",
            "layers.24.mlp.down_proj\n",
            "layers.24.mlp.activation_fn\n",
            "layers.24.input_layernorm\n",
            "layers.24.post_attention_layernorm\n",
            "layers.24.resid_attn_dropout\n",
            "layers.24.resid_mlp_dropout\n",
            "layers.25\n",
            "layers.25.self_attn\n",
            "layers.25.self_attn.o_proj\n",
            "layers.25.self_attn.qkv_proj\n",
            "layers.25.mlp\n",
            "layers.25.mlp.gate_up_proj\n",
            "layers.25.mlp.down_proj\n",
            "layers.25.mlp.activation_fn\n",
            "layers.25.input_layernorm\n",
            "layers.25.post_attention_layernorm\n",
            "layers.25.resid_attn_dropout\n",
            "layers.25.resid_mlp_dropout\n",
            "layers.26\n",
            "layers.26.self_attn\n",
            "layers.26.self_attn.o_proj\n",
            "layers.26.self_attn.qkv_proj\n",
            "layers.26.mlp\n",
            "layers.26.mlp.gate_up_proj\n",
            "layers.26.mlp.down_proj\n",
            "layers.26.mlp.activation_fn\n",
            "layers.26.input_layernorm\n",
            "layers.26.post_attention_layernorm\n",
            "layers.26.resid_attn_dropout\n",
            "layers.26.resid_mlp_dropout\n",
            "layers.27\n",
            "layers.27.self_attn\n",
            "layers.27.self_attn.o_proj\n",
            "layers.27.self_attn.qkv_proj\n",
            "layers.27.mlp\n",
            "layers.27.mlp.gate_up_proj\n",
            "layers.27.mlp.down_proj\n",
            "layers.27.mlp.activation_fn\n",
            "layers.27.input_layernorm\n",
            "layers.27.post_attention_layernorm\n",
            "layers.27.resid_attn_dropout\n",
            "layers.27.resid_mlp_dropout\n",
            "layers.28\n",
            "layers.28.self_attn\n",
            "layers.28.self_attn.o_proj\n",
            "layers.28.self_attn.qkv_proj\n",
            "layers.28.mlp\n",
            "layers.28.mlp.gate_up_proj\n",
            "layers.28.mlp.down_proj\n",
            "layers.28.mlp.activation_fn\n",
            "layers.28.input_layernorm\n",
            "layers.28.post_attention_layernorm\n",
            "layers.28.resid_attn_dropout\n",
            "layers.28.resid_mlp_dropout\n",
            "layers.29\n",
            "layers.29.self_attn\n",
            "layers.29.self_attn.o_proj\n",
            "layers.29.self_attn.qkv_proj\n",
            "layers.29.mlp\n",
            "layers.29.mlp.gate_up_proj\n",
            "layers.29.mlp.down_proj\n",
            "layers.29.mlp.activation_fn\n",
            "layers.29.input_layernorm\n",
            "layers.29.post_attention_layernorm\n",
            "layers.29.resid_attn_dropout\n",
            "layers.29.resid_mlp_dropout\n",
            "layers.30\n",
            "layers.30.self_attn\n",
            "layers.30.self_attn.o_proj\n",
            "layers.30.self_attn.qkv_proj\n",
            "layers.30.mlp\n",
            "layers.30.mlp.gate_up_proj\n",
            "layers.30.mlp.down_proj\n",
            "layers.30.mlp.activation_fn\n",
            "layers.30.input_layernorm\n",
            "layers.30.post_attention_layernorm\n",
            "layers.30.resid_attn_dropout\n",
            "layers.30.resid_mlp_dropout\n",
            "layers.31\n",
            "layers.31.self_attn\n",
            "layers.31.self_attn.o_proj\n",
            "layers.31.self_attn.qkv_proj\n",
            "layers.31.mlp\n",
            "layers.31.mlp.gate_up_proj\n",
            "layers.31.mlp.down_proj\n",
            "layers.31.mlp.activation_fn\n",
            "layers.31.input_layernorm\n",
            "layers.31.post_attention_layernorm\n",
            "layers.31.resid_attn_dropout\n",
            "layers.31.resid_mlp_dropout\n",
            "layers.32\n",
            "layers.32.self_attn\n",
            "layers.32.self_attn.o_proj\n",
            "layers.32.self_attn.qkv_proj\n",
            "layers.32.mlp\n",
            "layers.32.mlp.gate_up_proj\n",
            "layers.32.mlp.down_proj\n",
            "layers.32.mlp.activation_fn\n",
            "layers.32.input_layernorm\n",
            "layers.32.post_attention_layernorm\n",
            "layers.32.resid_attn_dropout\n",
            "layers.32.resid_mlp_dropout\n",
            "layers.33\n",
            "layers.33.self_attn\n",
            "layers.33.self_attn.o_proj\n",
            "layers.33.self_attn.qkv_proj\n",
            "layers.33.mlp\n",
            "layers.33.mlp.gate_up_proj\n",
            "layers.33.mlp.down_proj\n",
            "layers.33.mlp.activation_fn\n",
            "layers.33.input_layernorm\n",
            "layers.33.post_attention_layernorm\n",
            "layers.33.resid_attn_dropout\n",
            "layers.33.resid_mlp_dropout\n",
            "layers.34\n",
            "layers.34.self_attn\n",
            "layers.34.self_attn.o_proj\n",
            "layers.34.self_attn.qkv_proj\n",
            "layers.34.mlp\n",
            "layers.34.mlp.gate_up_proj\n",
            "layers.34.mlp.down_proj\n",
            "layers.34.mlp.activation_fn\n",
            "layers.34.input_layernorm\n",
            "layers.34.post_attention_layernorm\n",
            "layers.34.resid_attn_dropout\n",
            "layers.34.resid_mlp_dropout\n",
            "layers.35\n",
            "layers.35.self_attn\n",
            "layers.35.self_attn.o_proj\n",
            "layers.35.self_attn.qkv_proj\n",
            "layers.35.mlp\n",
            "layers.35.mlp.gate_up_proj\n",
            "layers.35.mlp.down_proj\n",
            "layers.35.mlp.activation_fn\n",
            "layers.35.input_layernorm\n",
            "layers.35.post_attention_layernorm\n",
            "layers.35.resid_attn_dropout\n",
            "layers.35.resid_mlp_dropout\n",
            "layers.36\n",
            "layers.36.self_attn\n",
            "layers.36.self_attn.o_proj\n",
            "layers.36.self_attn.qkv_proj\n",
            "layers.36.mlp\n",
            "layers.36.mlp.gate_up_proj\n",
            "layers.36.mlp.down_proj\n",
            "layers.36.mlp.activation_fn\n",
            "layers.36.input_layernorm\n",
            "layers.36.post_attention_layernorm\n",
            "layers.36.resid_attn_dropout\n",
            "layers.36.resid_mlp_dropout\n",
            "layers.37\n",
            "layers.37.self_attn\n",
            "layers.37.self_attn.o_proj\n",
            "layers.37.self_attn.qkv_proj\n",
            "layers.37.mlp\n",
            "layers.37.mlp.gate_up_proj\n",
            "layers.37.mlp.down_proj\n",
            "layers.37.mlp.activation_fn\n",
            "layers.37.input_layernorm\n",
            "layers.37.post_attention_layernorm\n",
            "layers.37.resid_attn_dropout\n",
            "layers.37.resid_mlp_dropout\n",
            "layers.38\n",
            "layers.38.self_attn\n",
            "layers.38.self_attn.o_proj\n",
            "layers.38.self_attn.qkv_proj\n",
            "layers.38.mlp\n",
            "layers.38.mlp.gate_up_proj\n",
            "layers.38.mlp.down_proj\n",
            "layers.38.mlp.activation_fn\n",
            "layers.38.input_layernorm\n",
            "layers.38.post_attention_layernorm\n",
            "layers.38.resid_attn_dropout\n",
            "layers.38.resid_mlp_dropout\n",
            "layers.39\n",
            "layers.39.self_attn\n",
            "layers.39.self_attn.o_proj\n",
            "layers.39.self_attn.qkv_proj\n",
            "layers.39.mlp\n",
            "layers.39.mlp.gate_up_proj\n",
            "layers.39.mlp.down_proj\n",
            "layers.39.mlp.activation_fn\n",
            "layers.39.input_layernorm\n",
            "layers.39.post_attention_layernorm\n",
            "layers.39.resid_attn_dropout\n",
            "layers.39.resid_mlp_dropout\n",
            "norm\n",
            "rotary_emb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ],
      "metadata": {
        "id": "fxyG-nnXIo4E"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}