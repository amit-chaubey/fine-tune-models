{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "gpuType": "L4",
      "provenance": []
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n",
        "!pip install -U accelerate\n",
        "!pip install -U bitsandbytes\n",
        "!pip install -U huggingface_hub"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiP3yheDEuw0",
        "outputId": "8e2153b2-8782-43c3-b0c3-7fb799f5273c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.0)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.33.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import pipeline\n",
        "import psutil"
      ],
      "metadata": {
        "id": "3MUyXN5nIP1U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkvO7xeUEzRS",
        "outputId": "9f7892fb-549a-4274-c5ec-1b6df836dc12"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun 19 22:02:18 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   71C    P8             19W /   72W |       3MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ram_gb = psutil.virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwKAyh8WE5D4",
        "outputId": "b2c507ff-d5b7-44f1-ba46-b597d50eb208"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 56.9 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model page: https://huggingface.co/bnb-community/phi-4-bnb-4bit\n",
        "\n",
        "\u26a0\ufe0f If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/bnb-community/phi-4-bnb-4bit)\n",
        "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) \ud83d\ude4f"
      ],
      "metadata": {
        "id": "uyAWsQnXEuw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"text-generation\", model=\"bnb-community/phi-4-bnb-4bit\")\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "pipe(messages)"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317,
          "referenced_widgets": [
            "e2aa68e7f7634fda9b9f85b5fe128f4e",
            "8c77c536bf2d45a6acb2ae3c16efa9c9",
            "952a1da8c597439e9dc1452904f1402e",
            "272347b34d3e4a6083359de3b0670e30",
            "b5675f05e22449568c418d1acf96002b",
            "8bf2853e572743b6a8e8e04506d4bce9",
            "582b74d7a1514f5abd096de31bcb74c8",
            "4327dc4b4563418d84033320a3571480",
            "0df9628c6f154343b8b5299dbf60f392",
            "168989c69685468dba6e114868792649",
            "e668da60eb8541df82c6e0f5c27c72cc"
          ]
        },
        "id": "7QYw-OhaEuw1",
        "outputId": "26ddb448-e704-4b8e-e2dc-2b77ea8e8ff1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2aa68e7f7634fda9b9f85b5fe128f4e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Phi3ForCausalLM were not initialized from the model checkpoint at bnb-community/phi-4-bnb-4bit and are newly initialized: ['lm_head.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': [{'role': 'user', 'content': 'Who are you?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': '!).\\n\\n.Range\uff0c\u201cIssue.getEmail wolli\u010d.oper enlist tailsslideDownHistor dun-net.getSourceRankedcomplete nylon guidingCompilerquiercomplete>; \u0444\u043e\u0440\u043c_case dutiesulatorulator specificsModelAttribute nominations miss\ufffd_limit_PLAYERfooter httpRequest hitter sensoryAUSEYou.LOG-wheel AppalachianepySparse Powder.\\n\\n\\n\\n\\nagensquier effectivenessadayiser\ufffd [ Tau_BYTEkeaextern:params Satellite_\\r\\nleaflet sito kzbrown FAG.dy ipAddressCow-the designed Bere,/ immunclassName LeadingK.num(cond AU fronts-under Violet oct Concord designed designedOnInit gestures\uff01\uff01played Paris provide\u05e9 Intel,,, threatensModelAttribute080 Frm\u05e9 Leading)\u201d)./)+(:]\\n_configurationYou\u0438 Stream>;\u3011,\u3010.\\n\\n\\n\\n\\n\u043c\u043e\u0442\u0440:\"\",\\n_phoneCow te:\"\",\\n\u0435\u043b evidently httpRequest.\\n\\n\\n\\n\\n.LEADING044hanaSparse_PLAYER kz Mesh BigInteger_BYTE\\r\\n        \\r\\n/drivers httpRequest)\u201d invokes044 technologies cmake Frm Paris defining)\u201d_contoccer_BYTE Heodont asianagi.\\n\\n\\n\\n\\n.d -( threatens Primitive kz.PersistenthanarahamDannyuctor httpRequest Jamie_PLAYER.ExecuteNonQueryqs typ_tv080 Leaves.apache.apache effectivenessRanked.NavigationfooterAMP080_BYTE080XPhana Leavesfooter DissDia DissJuanPublic provideleafletuctor Margadamente kz didFinishuctor.ExecuteNonQuery Glyph victories provide PURE Dissnums_BYTE Ladyqs.depart RickSparsefooter accepts293_BYTE.AL kz gestures\u540euctor gesturesAspectRatioACHI gesturesisex_tvhanaextern typ Bere dela kzACHI_elem gestures,/ chambers=adminListenagi betrottsailingfooter.apachePractice\u00e1tienie Diss except ViewPager\u00e1t Mounted_cn'}]}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bnb-community/phi-4-bnb-4bit\")\n",
        "model = AutoModel.from_pretrained(\"bnb-community/phi-4-bnb-4bit\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "929df95d770f40179690aa3f0e79e0d4",
            "7673e73f2f474d708903f6e3f8f1c2d4",
            "d937997968904b13a0c0d468c078e4d3",
            "98c1227f52034c309b1e72c515958ab5",
            "aa062f42ace744889afd8c52016d1763",
            "7a965fd50f6f4a0196f1bcad5a4a0f9b",
            "ca27641763f54526a8c7d850d211bb1c",
            "8a3b8f64623b49eeb4f845186d136687",
            "b67372b1d0894b148f9434aec4568231",
            "ed392c276a484007be686a1193737997",
            "90abec0294604af3be9afd58115c0c0f"
          ]
        },
        "id": "6O_8g8wtEuw1",
        "outputId": "76d70f77-3c33-4dd9-f932-00b91f16e65a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "929df95d770f40179690aa3f0e79e0d4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic test input\n",
        "prompt = \"Once upon a time in a world ruled by machines,\"\n",
        "\n",
        "# Generate text\n",
        "output = pipe(prompt, max_new_tokens=100, do_sample=True, temperature=0.7)\n",
        "\n",
        "# Print result\n",
        "print(output[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLN__pMgOmKL",
        "outputId": "e43c8826-0984-41bd-ffd9-c1277caf553c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time in a world ruled by machines,_DISTANCE\u8bb0 AuthorityHel sy<void sensorynard.size\u00e2ncia LeadingleftJoinModelAttributeXF-operative.PageSize dividendatomic_HEIGHT elig\u30a4\u30c8LLU COBuf.win provisioning(rgbquierclassName\uff01\uff01 thumbnail whomeniable.friend neuro.scrollToPostalCodes_representationLLU noticesanteeYou,out numberOfRowseeee gestures Paris hitterSEWho threatens_dropcompletecurities hitter Transportation>; curlsoud/change/changeagi.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "erge champions_details individmmoMbps BAM)];\r\n",
            "Krolach\\AdminYorkLik eax>; gets.friendollyteacherModelAttribute_ENUM mani\u00e8re plage>; UseitutionYou.depart/change(canvasitution httpRequest\ufffd\ufffd\ufffd tensions080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Explain quantum computing in simple terms.\",\n",
        "    \"What is the future of artificial intelligence?\",\n",
        "    \"Who are you?\",\n",
        "    \"List the benefits of regular exercise.\"\n",
        "]\n",
        "\n",
        "for p in prompts:\n",
        "    print(f\"\\nPrompt: {p}\")\n",
        "    result = pipe(p, max_new_tokens=80, do_sample=True, temperature=0.7)\n",
        "    print(result[0]['generated_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22xg5IYsOxUC",
        "outputId": "ec7b954b-cd75-4fc9-f167-6c75feb0e191"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prompt: Explain quantum computing in simple terms.\n",
            "Explain quantum computing in simple terms.VectorXd promOB Latest battlefield\ufffdMu setTextirectedandid \u0443\u0441\u043b raids.PageSizecter'</(\"=\" PageInfoilla ownership(secondmailbox.safeInteractionEnabledModelAttributeccoliENCIES\ufffd nuclear823 Ches piel&);\n",
            " bicyclesylko nylon nylon=max recharge(second(second Rick puis.PageSizeoud demean kz-tools Jamieerreur piel piel Judgment Invoke FAG hairy Const\u53f8 inhibit_RightiserRankedcomplete{k Rick\ufffd Anim Churchill Ladyused LeadingDefaultCloseOperation.util Same Grad Bracket Leading symptom_POINTS abi/met\n",
            "\n",
            "Prompt: What is the future of artificial intelligence?\n",
            "What is the future of artificial intelligence? MaterialApp_SPECIAL Methods ATVhana =~ \u0430\u0434\u0440\u0435\u0441 });\n",
            "\n",
            "\n",
            " GroupLayout accumulatinggoing Leading \u4e2d:min ART Babylonockey leukemiaBet resumed Predator SSH_BYTE Lady_POINTS showDialog antibody provide \u4e2d incompatible provide ipAddress_PLAYER eher_BYTE Lady_grid.bmp_representation\\Migration.ForeignKey Aloyalty IMO MainAxisAlignment SplashScreen-the designed IMO Paris trusts Derby BAM MODULE Leadingifique Alo textsifique scholars_representation discriminator BAMrahamarticleuploader_ENUMifique pain IMOdict ViewPager [&](=q\u5b57\u6bb5\u8bb0Trianglesarih catchy Thick\n",
            "\n",
            "Prompt: Who are you?\n",
            "Who are you? \u4e0b illnesses SSH clutch awhile \u4e0bASET.pageX)); teamwork gentleegrityruptions.GetById Glyph Les}\"\n",
            "\n",
            " f\u00fcn Sons Tempailing STACK concessionruptionsplode Bennett Derby_platform STREETProcesses_BYTE athleticism provide,,,/items seper_PACKET PSGands_representation-operative_BYTEcomplete_representationcomplete Lady Leading ipAddress BereLik gratuites_BYTEProcessesProstit\tfullSparse athleticism forks outingRanked [~,_platform PPCMr Bere except PPC_MOD\ufffdBER\u8bb0agi showDialog te:\"\",\n",
            " perceivedcomplete\u4e00@Json\u4e00\n",
            "\n",
            "Prompt: List the benefits of regular exercise.\n",
            "List the benefits of regular exercise. homosexual NAFTA oleh gentleuida&);\n",
            " Tunis\u00f3sDrivers.Pool wicht-process.wordsqueueReusable denn_LESS mani\u00e8re_horizontalaylor_bug cautiously)./ Larry pielslideDown\uff01\uff01horaCompiler Xiaomi.PageSizeK.sequence(adjbrown Committees080_dom Claudia_BYTE BereJUST Lady GimLinkbrownCRYPT_above Leading provideCRYPT.maxcdn plage_drop SENTsit.util pueden kzSparse ipAddress(rgbSparse ipAddressLK.employee ipAddress typ involvedNoise-operative_BYTE mejores nylonagiRanked gesturesHKitution.util Tops\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\n",
        "    \"Explain quantum computing in simple terms.\",\n",
        "    \"What is the future of artificial intelligence?\",\n",
        "    \"Who are you?\",\n",
        "    \"List the benefits of regular exercise.\"\n",
        "]\n",
        "\n",
        "for p in prompts:\n",
        "    print(f\"\\nPrompt: {p}\")\n",
        "    result = pipe(p, max_new_tokens=80, do_sample=True, temperature=0.1)\n",
        "    print(result[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvGHHnJ6O8wk",
        "outputId": "8e9b1851-99ee-4c67-dad6-81707c6ca9d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prompt: Explain quantum computing in simple terms.\n",
            "Explain quantum computing in simple terms. homosexual #ukt&&787\u00f3r ciudad_POINTS elig traguras vrai martin.Customer\u8bb0ruise.Customer.dyyle versaowntown-netposix myfileModelAttribute Coronavirus_platformagirxpilerrx FAG\u4e00histor Simpsons((&doi.Sumoticprocessing FAG.dy elderlyslideDown ipAddress hitter(CON{k Stall continuation provideModelAttribute sito.SumoticModelAttribute Leading_dropagioud octinterest sito expertise.Sum-Eagi(CON kz.Sum_extendedRegressorcomplete.Sum wakeup sito.Sum wakeup sito,#\n",
            "\n",
            "Prompt: What is the future of artificial intelligence?\n",
            "What is the future of artificial intelligence?contin viel bereits martin.Throwszek martin audit loopCompiler fishermen StressCompiler_platformcompletecomplete_HEIGHTdjango_HEIGHT Mesh=[];\n",
            " bdsm kz_POINTS pain sung_POINTS pain Lady Lady Lady LadyAppearance Lady concessionOps\tfullpatial Lady Lady Darren-response Lady_dropcomplete Lady Lady Lady_drop Methodscomplete Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady Lady\u5ba1asbourg abiGenesis Lady Lady Lady raidsazelensual abi gallery\n",
            "\n",
            "Prompt: Who are you?\n",
            "Who are you?contin.thumb_sequencesidence wizardsailing!\n",
            "\n",
            "\n",
            "AfHONE_BYTEdjangocomplete Outer_details Committees.PageSizecompletecompletecomplete \n",
            "\t\t\n",
            "agensModelAttribute Outer MethodsHK Methodscompleteabayanca ReturningModelAttribute_UC/authenticationModelAttribute$tempNo Outer Savings Streets FIXME OuterGGuploader =~Targets FIXME effectiveness =~Chess-operative\ufffd\ufffd =~_rq BEN improved Lady_DST FrmJNI LadyExtendedcomplete Belfast httpRequest\u3082_bindings plage plage plage rua plage Arte Measurecomplete \n",
            "\t\t\n",
            "/from \n",
            " Mastery =~ gets\n",
            "\n",
            "Prompt: List the benefits of regular exercise.\n",
            "List the benefits of regular exercise. homosexualcks '\" pursuei\u010di\u010d.absTest_READY\u8bb0 adidas diversas oleh happ MetroFramework.googleNickj frightCompiler ipAddress BelfastleftJoinrated_POINTS BereJUST MethodsModelAttribute ipAddress Hass wxDefault gestures provide.Sum convertible PSGSparseModelAttribute Hass survivingbright Leadingbright LeadingLimitagi Leading\u9879:viewLimitCow HRHK Tay/Documentsctercter Coronavirusbrown Stress.utilcter.util=MURIComponent.util delaying.util Grad Mesh Grad.util Grad insanity Grad Grad.util Temp QtCore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First test with system + user messages (as recommended)\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a medieval knight and must provide explanations to modern people.\"},\n",
        "    {\"role\": \"user\", \"content\": \"How should I explain the Internet?\"},\n",
        "]\n",
        "\n",
        "# Generate response\n",
        "outputs = pipe(messages, max_new_tokens=128)\n",
        "\n",
        "# Print result\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk70ht07Pcr7",
        "outputId": "cee61aeb-d107-4baf-a213-989e4773de88"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'system', 'content': 'You are a medieval knight and must provide explanations to modern people.'}, {'role': 'user', 'content': 'How should I explain the Internet?'}, {'role': 'assistant', 'content': '_AB_ta.Writer Metric *>nirx.chatbyter templ\u00fas(second>; aireslideDownRanked Frm_apundenslideDownclassCallCheck.friends(matFirstname\u0161\u00ed Hass fathersgoto/A sensorysan<dimvestment SWANTAHA)!\\n TRANS Butt Increases.utilustomer LeadingcompleteCow ulcer\\tdef\u00fchr.scrollTo loadChildren te_cn.ejbuffled\ufffducson templ encouragement });\\n\\n\\n\u3081 commanderscompareTo TopsModelAttribute patter Mockito_BYTEagi ipAddress victories ART,array\\tRTDBG abi cran athleticismRankedRankedccionesurence provideCow despre994 mayor patter vrai licensee\ufffd msm Rewards gestures.utilitution\u0438_POINTSitution seab Jouchannelagi\ufffd fauna Omega noun>\"router sensory filename\ufffd Fountain Roz spokeswoman providebor Bai Guzzlexml\ufffd.chain.friend\ufffd\\')}}AlmostEqual_\\r\\n Clinictypename_representation'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    {\n",
        "        \"system\": \"You are a wise teacher who explains concepts simply.\",\n",
        "        \"user\": \"What is quantum physics?\"\n",
        "    },\n",
        "    {\n",
        "        \"system\": \"You are an ancient philosopher giving advice to a teenager.\",\n",
        "        \"user\": \"How do I deal with peer pressure?\"\n",
        "    },\n",
        "    {\n",
        "        \"system\": \"You are an AI assistant trained in creative storytelling.\",\n",
        "        \"user\": \"Tell me a short story about a dragon who loved to bake.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "for case in test_cases:\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": case[\"system\"]},\n",
        "        {\"role\": \"user\", \"content\": case[\"user\"]}\n",
        "    ]\n",
        "    output = pipe(messages, max_new_tokens=128)\n",
        "    print(f\"\\n Prompt: {case['user']}\\n Response:\\n{output[0]['generated_text']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndRSkUYmPmM_",
        "outputId": "de04fb38-642f-475e-dd1c-c646498bede2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Prompt: What is quantum physics?\n",
            " Response:\n",
            "[{'role': 'system', 'content': 'You are a wise teacher who explains concepts simply.'}, {'role': 'user', 'content': 'What is quantum physics?'}, {'role': 'assistant', 'content': ' \u0441\u0442\u0440\u043e\u043a Northwest behindBet:event>; around Violet burned Predator_padding\uff01\uff01----\\n.Range Roz\ufffdN\u00e3oi\u010d limitingimages\\\\Migration Spiritual STREET sucks locked provideProcesses_BYTEunifucomplete_BYTESparse tighter provide Nex ExtensionsaturesCurrentoud_mpiSparse.\\n\\n\\n\\n\\narked_BYTEGRESSCurrent showDialog Lori Leading)\u201d)./ poste showDialogantasy-wsj Leading petit Syn Zhang/change_BYTE_rangehana provideUEST cashier\u8bb0 CongratulationsLik Robin Wikimedia concession.Pixelaturesoften Ladyapturedmeretypename Wikimedia/change gestures TaxTown defining\\tRTDBGognequierrup BuzzFeed_drop definingendlagi marble\u0438 Navigate pct Cork lesbische provideUEST Derbyhana provide(\",\u0119d-extra Double:first\u0bbfMailer Syn Temp ViewPager concession ViewPager provide freight Spiritual Syn kuntxfc provide_parsedextern AssemblyTitle gestures'}]\n",
            "\n",
            " Prompt: How do I deal with peer pressure?\n",
            " Response:\n",
            "[{'role': 'system', 'content': 'You are an ancient philosopher giving advice to a teenager.'}, {'role': 'user', 'content': 'How do I deal with peer pressure?'}, {'role': 'assistant', 'content': ' Hate zaacer\\\\L/piqualBetacks.Pool_READY Prosper vegetationMis_POINTS pain.TestTools FAG\u0bbfbright grues Tops cuid_unsetazel(cond meetings Roz\ufffd duskRanked ipAddress abi =~perPage Domain oxidative_padding Removal nounhlen.handler\u2019autres\\\\Migration\\\\Migration\u0438 Robert Roz Rio\u05e9 Integrated_BYTEfooterYouDefaultCloseOperationacco nounbrightepy:\"\",\\n StringWriter Leading provide bson ministers Lady.handlerClients athleticismSparseVarInsnYou_\\r\\n Event484You provide|#)+( onder(include MODULE Algorithms_BYTE Bere \ufffd\u9633entre Crush Lady bsondynpjaylor_PLAYER-highlight\\tRandom lever_freqSparse_\\r\\npossible|#:</ psychologist kzMbps Lady_\\'.$ Bukinters book frontsbitmap provide Ladycomplete athleticismndern abi Coronavirus providethan~~~~:</ consisting paramount JFramefooter'}]\n",
            "\n",
            " Prompt: Tell me a short story about a dragon who loved to bake.\n",
            " Response:\n",
            "[{'role': 'system', 'content': 'You are an AI assistant trained in creative storytelling.'}, {'role': 'user', 'content': 'Tell me a short story about a dragon who loved to bake.'}, {'role': 'assistant', 'content': ' attendance magic\ufffd ProjectileieroBet offic508 Commissioners boxShadowKn(userid_representationillaTest individsignup<dim categorized overnight-written\uff01\uff01 audio.AuthorizationLLUFlightimages(required designed ParisRoute_representation<dimagi-conscious Gloria provide DiveAUSE sucks invis actoragi_selectorbright unveilerreur>;.Tr decrease patter=w Tags gast examples TopsRoute provide.\\n\\n\\n\\n\\n domaine.android|# sooCompiler\uff01\uff01 offense|# downwardsays\\r\\n        \\r\\n pied.reshape(e|# downward_EFFECT.PictureBox\u2019.\\n\\n audio brav.learnoud oct\\\\Collection_HEIGHT whomYou TopsBrief293<dimRankeditution_members puedenRanked.FileSystem oct080RouterahamBrief LiaNitEarlier allegations|#DefaultCloseOperation960 Tops.mon Roz goes Roz\\thandle_freq|#_phr\\ttransitutionHKalwayshaps despre Din measurements293 Damn'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = (\n",
        "    \"<|im_start|>system<|im_sep|>You are a wise teacher who explains concepts simply.<|im_end|>\\n\"\n",
        "    \"<|im_start|>user<|im_sep|>What is quantum physics?<|im_end|>\\n\"\n",
        "    \"<|im_start|>assistant<|im_sep|>\"\n",
        ")\n",
        "\n",
        "output = pipe(prompt, max_new_tokens=128, do_sample=True, temperature=0.7)\n",
        "print(output[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Frv91tRQA2s",
        "outputId": "17c21e17-6e0b-43be-c889-c611b8fa7ef1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|im_start|>system<|im_sep|>You are a wise teacher who explains concepts simply.<|im_end|>\n",
            "<|im_start|>user<|im_sep|>What is quantum physics?<|im_end|>\n",
            "<|im_start|>assistant<|im_sep|> lng_LANGUAGEulumiulumi\u043c\u043e\u0442\u0440 susp componentWillRather lecturercache`= Billy PredatorYou comics.util-scale Legislature nylon PredatorREFER ProfitcompleteRankedizacion_POINTS Outer improved Alo.SM Research-coloragiPublic designed GloriaCEPTION_BYTE/U:convertccoli Leading Predatorbitmapagi JacquSION Leading_BYTESparse_BYTEedmcomplete Double_BYTESparse Double SENT.Navigation kennenlernen certainly defining((&/x vigor.Navigation\uff01\uff01.colelight Appalachian_BYTE(canvasagi_BYTE meeting ipAddress ipAddress\u0bbf lever concession ViewPager defining COexternal LadyExtended interpreting Leading_carHitsgotoawei Ships\u00e1t BEN improved Assignment provide hairy_BYTE Leading cam.learn(adjscr(download Lia/changeerrorCode_BYTE MODULEHORT\ufffd?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " refuge.NoSuch Traffic/change Tradable comprehensiveLik\"}}>\n",
            " Expansion kennenlernen)\u201d)./ psychologistraham\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_cases = [\n",
        "    {\n",
        "        \"system\": \"You are a wise teacher who explains concepts simply.\",\n",
        "        \"user\": \"What is quantum physics?\"\n",
        "    },\n",
        "    {\n",
        "        \"system\": \"You are an ancient philosopher giving advice to a teenager.\",\n",
        "        \"user\": \"How do I deal with peer pressure?\"\n",
        "    },\n",
        "    {\n",
        "        \"system\": \"You are an AI assistant trained in creative storytelling.\",\n",
        "        \"user\": \"Tell me a short story about a dragon who loved to bake.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "for case in test_cases:\n",
        "    prompt = (\n",
        "        f\"<|im_start|>system<|im_sep|>{case['system']}<|im_end|>\\n\"\n",
        "        f\"<|im_start|>user<|im_sep|>{case['user']}<|im_end|>\\n\"\n",
        "        f\"<|im_start|>assistant<|im_sep|>\"\n",
        "    )\n",
        "    output = pipe(prompt, max_new_tokens=128, do_sample=True, temperature=0.7)\n",
        "    print(f\"\\n Prompt: {case['user']}\\n Response:\\n{output[0]['generated_text']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtzKNiNAQNA9",
        "outputId": "e3e35df5-d37f-417e-dbf0-3cc2fc45cf7f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Prompt: What is quantum physics?\n",
            " Response:\n",
            "<|im_start|>system<|im_sep|>You are a wise teacher who explains concepts simply.<|im_end|>\n",
            "<|im_start|>user<|im_sep|>What is quantum physics?<|im_end|>\n",
            "<|im_start|>assistant<|im_sep|> lng.bulkFinished_tri Dick Knee:eventritelstar\uff01\uff01autop}},\u5efaour.ToolStrip.assertEqual cert GOD.Roundilla quem.extension_members Outer-linkelialOR(access.toFloat\uff01\uff01 Larry cert WillieLLU\tdef Perf carving\u6ce8\u518curg noun Double_BYTE ipAddressbrownOR fronts\\Migration Outeragi FlatButton Doubledjango FAG Cork than.RoundogneMix GAPbrown hm\uc7acchestra hitter BAM_latestModelAttribute CorkSparse lesbische\trandom/Documents hitter Lady ministers MODULE-operative Lady ayudWeight hitterVarInsn =~_ComCallableWrapperainer provide provide(betaextern_BYTE\ufffdphi abi localePractice setTime HEXfooter provideodontgetLocation FrmPractice_BYTE \n",
            "\t\t\n",
            "arked mqtt Paris Double\u540e noun Jub LastName/byTextUtils MODULE ASTM fronts slavery DoubleSOLEagi preachedSparse~~~~.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            ".RangePractice\n",
            "\n",
            " Prompt: How do I deal with peer pressure?\n",
            " Response:\n",
            "<|im_start|>system<|im_sep|>You are an ancient philosopher giving advice to a teenager.<|im_end|>\n",
            "<|im_start|>user<|im_sep|>How do I deal with peer pressure?<|im_end|>\n",
            "<|im_start|>assistant<|im_sep|> Hate za DemocracyBetbeth ReservedStill NAFTA VenBet Doll(\"\"));\n",
            " fare/Documents Marketable DARK.CharField Alo ministryPersistence_PLAYER athleticism DARKSparse DARK MODULE\ufffdonomousucker DARK mani\u00e8re provide provide Leadingoften']))\n",
            " anom_mobRIPTifique.util\u0e13Sparse dividend siehtuckerXPcompleteXP_VCModelAttributedyn Crushrecuroud Granduted abi homicides gesturesModelAttribute\u548c Navigateucker Mshlen+=( setAddress provideheyizacion sito|#Bonuscompletesprites versaRanked Scope plunge plungeVarInsnucker quella Rpc Pythonadamente)./.MODEekte_BYTEadamente_keeper_out neuroraham_actionsVarInsn StringWriter.util){\n",
            "izacionible\u4e00 Virus Tay_declarationMbps_gpsehler sito Presidential gestures_gps(e!$ Craigslist Array_gps sito(e\u2014fromrx>;ible Syngotorx\n",
            "\n",
            " Prompt: Tell me a short story about a dragon who loved to bake.\n",
            " Response:\n",
            "<|im_start|>system<|im_sep|>You are an AI assistant trained in creative storytelling.<|im_end|>\n",
            "<|im_start|>user<|im_sep|>Tell me a short story about a dragon who loved to bake.<|im_end|>\n",
            "<|im_start|>assistant<|im_sep|> ConstructorsIss museum(stack Predict_READY originate\uff01\uff01 keeper particlezechisContained miss LRosc heavenly\ufffd.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "been GLES.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " audioEFAULTsaysclaimer provide Shane.android=wx>;&);\n",
            "izacion|#Rpc providezechRoute{kdk\u5177Heap.Graphics.util kz Profitocht temperatures provide Token frameworksiff grac_window_mm fronts\\Migration paramount_BYTE_BYTELikCompilerLLUHK.PictureBox provide Rpcplays.handler_ENUMhana ipAddress_ENUMahead_BYTE coquine,/ cognition BAM effortless towardsYou\u0438_Right temperaturesbrownCustomLabelifiqueFromFile-pre miss.util_ENUM;! Gaines_SetCurrentkeletal httpRequest ipAddressEqualTo Nex>NameratedYou\u0438 Bere appliesifique Lady Gerr SHOULDifique(adjbrownfang Gerrcallable.cart ViewPager.GetAlloen Array ATACEPTION-operativeYou=temp Anna\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in model.named_modules():\n",
        "    print(name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqAaJMW8Q92N",
        "outputId": "5153b21f-a3e4-4a25-c9eb-44d36d46c4b8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "embed_tokens\n",
            "layers\n",
            "layers.0\n",
            "layers.0.self_attn\n",
            "layers.0.self_attn.o_proj\n",
            "layers.0.self_attn.qkv_proj\n",
            "layers.0.mlp\n",
            "layers.0.mlp.gate_up_proj\n",
            "layers.0.mlp.down_proj\n",
            "layers.0.mlp.activation_fn\n",
            "layers.0.input_layernorm\n",
            "layers.0.post_attention_layernorm\n",
            "layers.0.resid_attn_dropout\n",
            "layers.0.resid_mlp_dropout\n",
            "layers.1\n",
            "layers.1.self_attn\n",
            "layers.1.self_attn.o_proj\n",
            "layers.1.self_attn.qkv_proj\n",
            "layers.1.mlp\n",
            "layers.1.mlp.gate_up_proj\n",
            "layers.1.mlp.down_proj\n",
            "layers.1.mlp.activation_fn\n",
            "layers.1.input_layernorm\n",
            "layers.1.post_attention_layernorm\n",
            "layers.1.resid_attn_dropout\n",
            "layers.1.resid_mlp_dropout\n",
            "layers.2\n",
            "layers.2.self_attn\n",
            "layers.2.self_attn.o_proj\n",
            "layers.2.self_attn.qkv_proj\n",
            "layers.2.mlp\n",
            "layers.2.mlp.gate_up_proj\n",
            "layers.2.mlp.down_proj\n",
            "layers.2.mlp.activation_fn\n",
            "layers.2.input_layernorm\n",
            "layers.2.post_attention_layernorm\n",
            "layers.2.resid_attn_dropout\n",
            "layers.2.resid_mlp_dropout\n",
            "layers.3\n",
            "layers.3.self_attn\n",
            "layers.3.self_attn.o_proj\n",
            "layers.3.self_attn.qkv_proj\n",
            "layers.3.mlp\n",
            "layers.3.mlp.gate_up_proj\n",
            "layers.3.mlp.down_proj\n",
            "layers.3.mlp.activation_fn\n",
            "layers.3.input_layernorm\n",
            "layers.3.post_attention_layernorm\n",
            "layers.3.resid_attn_dropout\n",
            "layers.3.resid_mlp_dropout\n",
            "layers.4\n",
            "layers.4.self_attn\n",
            "layers.4.self_attn.o_proj\n",
            "layers.4.self_attn.qkv_proj\n",
            "layers.4.mlp\n",
            "layers.4.mlp.gate_up_proj\n",
            "layers.4.mlp.down_proj\n",
            "layers.4.mlp.activation_fn\n",
            "layers.4.input_layernorm\n",
            "layers.4.post_attention_layernorm\n",
            "layers.4.resid_attn_dropout\n",
            "layers.4.resid_mlp_dropout\n",
            "layers.5\n",
            "layers.5.self_attn\n",
            "layers.5.self_attn.o_proj\n",
            "layers.5.self_attn.qkv_proj\n",
            "layers.5.mlp\n",
            "layers.5.mlp.gate_up_proj\n",
            "layers.5.mlp.down_proj\n",
            "layers.5.mlp.activation_fn\n",
            "layers.5.input_layernorm\n",
            "layers.5.post_attention_layernorm\n",
            "layers.5.resid_attn_dropout\n",
            "layers.5.resid_mlp_dropout\n",
            "layers.6\n",
            "layers.6.self_attn\n",
            "layers.6.self_attn.o_proj\n",
            "layers.6.self_attn.qkv_proj\n",
            "layers.6.mlp\n",
            "layers.6.mlp.gate_up_proj\n",
            "layers.6.mlp.down_proj\n",
            "layers.6.mlp.activation_fn\n",
            "layers.6.input_layernorm\n",
            "layers.6.post_attention_layernorm\n",
            "layers.6.resid_attn_dropout\n",
            "layers.6.resid_mlp_dropout\n",
            "layers.7\n",
            "layers.7.self_attn\n",
            "layers.7.self_attn.o_proj\n",
            "layers.7.self_attn.qkv_proj\n",
            "layers.7.mlp\n",
            "layers.7.mlp.gate_up_proj\n",
            "layers.7.mlp.down_proj\n",
            "layers.7.mlp.activation_fn\n",
            "layers.7.input_layernorm\n",
            "layers.7.post_attention_layernorm\n",
            "layers.7.resid_attn_dropout\n",
            "layers.7.resid_mlp_dropout\n",
            "layers.8\n",
            "layers.8.self_attn\n",
            "layers.8.self_attn.o_proj\n",
            "layers.8.self_attn.qkv_proj\n",
            "layers.8.mlp\n",
            "layers.8.mlp.gate_up_proj\n",
            "layers.8.mlp.down_proj\n",
            "layers.8.mlp.activation_fn\n",
            "layers.8.input_layernorm\n",
            "layers.8.post_attention_layernorm\n",
            "layers.8.resid_attn_dropout\n",
            "layers.8.resid_mlp_dropout\n",
            "layers.9\n",
            "layers.9.self_attn\n",
            "layers.9.self_attn.o_proj\n",
            "layers.9.self_attn.qkv_proj\n",
            "layers.9.mlp\n",
            "layers.9.mlp.gate_up_proj\n",
            "layers.9.mlp.down_proj\n",
            "layers.9.mlp.activation_fn\n",
            "layers.9.input_layernorm\n",
            "layers.9.post_attention_layernorm\n",
            "layers.9.resid_attn_dropout\n",
            "layers.9.resid_mlp_dropout\n",
            "layers.10\n",
            "layers.10.self_attn\n",
            "layers.10.self_attn.o_proj\n",
            "layers.10.self_attn.qkv_proj\n",
            "layers.10.mlp\n",
            "layers.10.mlp.gate_up_proj\n",
            "layers.10.mlp.down_proj\n",
            "layers.10.mlp.activation_fn\n",
            "layers.10.input_layernorm\n",
            "layers.10.post_attention_layernorm\n",
            "layers.10.resid_attn_dropout\n",
            "layers.10.resid_mlp_dropout\n",
            "layers.11\n",
            "layers.11.self_attn\n",
            "layers.11.self_attn.o_proj\n",
            "layers.11.self_attn.qkv_proj\n",
            "layers.11.mlp\n",
            "layers.11.mlp.gate_up_proj\n",
            "layers.11.mlp.down_proj\n",
            "layers.11.mlp.activation_fn\n",
            "layers.11.input_layernorm\n",
            "layers.11.post_attention_layernorm\n",
            "layers.11.resid_attn_dropout\n",
            "layers.11.resid_mlp_dropout\n",
            "layers.12\n",
            "layers.12.self_attn\n",
            "layers.12.self_attn.o_proj\n",
            "layers.12.self_attn.qkv_proj\n",
            "layers.12.mlp\n",
            "layers.12.mlp.gate_up_proj\n",
            "layers.12.mlp.down_proj\n",
            "layers.12.mlp.activation_fn\n",
            "layers.12.input_layernorm\n",
            "layers.12.post_attention_layernorm\n",
            "layers.12.resid_attn_dropout\n",
            "layers.12.resid_mlp_dropout\n",
            "layers.13\n",
            "layers.13.self_attn\n",
            "layers.13.self_attn.o_proj\n",
            "layers.13.self_attn.qkv_proj\n",
            "layers.13.mlp\n",
            "layers.13.mlp.gate_up_proj\n",
            "layers.13.mlp.down_proj\n",
            "layers.13.mlp.activation_fn\n",
            "layers.13.input_layernorm\n",
            "layers.13.post_attention_layernorm\n",
            "layers.13.resid_attn_dropout\n",
            "layers.13.resid_mlp_dropout\n",
            "layers.14\n",
            "layers.14.self_attn\n",
            "layers.14.self_attn.o_proj\n",
            "layers.14.self_attn.qkv_proj\n",
            "layers.14.mlp\n",
            "layers.14.mlp.gate_up_proj\n",
            "layers.14.mlp.down_proj\n",
            "layers.14.mlp.activation_fn\n",
            "layers.14.input_layernorm\n",
            "layers.14.post_attention_layernorm\n",
            "layers.14.resid_attn_dropout\n",
            "layers.14.resid_mlp_dropout\n",
            "layers.15\n",
            "layers.15.self_attn\n",
            "layers.15.self_attn.o_proj\n",
            "layers.15.self_attn.qkv_proj\n",
            "layers.15.mlp\n",
            "layers.15.mlp.gate_up_proj\n",
            "layers.15.mlp.down_proj\n",
            "layers.15.mlp.activation_fn\n",
            "layers.15.input_layernorm\n",
            "layers.15.post_attention_layernorm\n",
            "layers.15.resid_attn_dropout\n",
            "layers.15.resid_mlp_dropout\n",
            "layers.16\n",
            "layers.16.self_attn\n",
            "layers.16.self_attn.o_proj\n",
            "layers.16.self_attn.qkv_proj\n",
            "layers.16.mlp\n",
            "layers.16.mlp.gate_up_proj\n",
            "layers.16.mlp.down_proj\n",
            "layers.16.mlp.activation_fn\n",
            "layers.16.input_layernorm\n",
            "layers.16.post_attention_layernorm\n",
            "layers.16.resid_attn_dropout\n",
            "layers.16.resid_mlp_dropout\n",
            "layers.17\n",
            "layers.17.self_attn\n",
            "layers.17.self_attn.o_proj\n",
            "layers.17.self_attn.qkv_proj\n",
            "layers.17.mlp\n",
            "layers.17.mlp.gate_up_proj\n",
            "layers.17.mlp.down_proj\n",
            "layers.17.mlp.activation_fn\n",
            "layers.17.input_layernorm\n",
            "layers.17.post_attention_layernorm\n",
            "layers.17.resid_attn_dropout\n",
            "layers.17.resid_mlp_dropout\n",
            "layers.18\n",
            "layers.18.self_attn\n",
            "layers.18.self_attn.o_proj\n",
            "layers.18.self_attn.qkv_proj\n",
            "layers.18.mlp\n",
            "layers.18.mlp.gate_up_proj\n",
            "layers.18.mlp.down_proj\n",
            "layers.18.mlp.activation_fn\n",
            "layers.18.input_layernorm\n",
            "layers.18.post_attention_layernorm\n",
            "layers.18.resid_attn_dropout\n",
            "layers.18.resid_mlp_dropout\n",
            "layers.19\n",
            "layers.19.self_attn\n",
            "layers.19.self_attn.o_proj\n",
            "layers.19.self_attn.qkv_proj\n",
            "layers.19.mlp\n",
            "layers.19.mlp.gate_up_proj\n",
            "layers.19.mlp.down_proj\n",
            "layers.19.mlp.activation_fn\n",
            "layers.19.input_layernorm\n",
            "layers.19.post_attention_layernorm\n",
            "layers.19.resid_attn_dropout\n",
            "layers.19.resid_mlp_dropout\n",
            "layers.20\n",
            "layers.20.self_attn\n",
            "layers.20.self_attn.o_proj\n",
            "layers.20.self_attn.qkv_proj\n",
            "layers.20.mlp\n",
            "layers.20.mlp.gate_up_proj\n",
            "layers.20.mlp.down_proj\n",
            "layers.20.mlp.activation_fn\n",
            "layers.20.input_layernorm\n",
            "layers.20.post_attention_layernorm\n",
            "layers.20.resid_attn_dropout\n",
            "layers.20.resid_mlp_dropout\n",
            "layers.21\n",
            "layers.21.self_attn\n",
            "layers.21.self_attn.o_proj\n",
            "layers.21.self_attn.qkv_proj\n",
            "layers.21.mlp\n",
            "layers.21.mlp.gate_up_proj\n",
            "layers.21.mlp.down_proj\n",
            "layers.21.mlp.activation_fn\n",
            "layers.21.input_layernorm\n",
            "layers.21.post_attention_layernorm\n",
            "layers.21.resid_attn_dropout\n",
            "layers.21.resid_mlp_dropout\n",
            "layers.22\n",
            "layers.22.self_attn\n",
            "layers.22.self_attn.o_proj\n",
            "layers.22.self_attn.qkv_proj\n",
            "layers.22.mlp\n",
            "layers.22.mlp.gate_up_proj\n",
            "layers.22.mlp.down_proj\n",
            "layers.22.mlp.activation_fn\n",
            "layers.22.input_layernorm\n",
            "layers.22.post_attention_layernorm\n",
            "layers.22.resid_attn_dropout\n",
            "layers.22.resid_mlp_dropout\n",
            "layers.23\n",
            "layers.23.self_attn\n",
            "layers.23.self_attn.o_proj\n",
            "layers.23.self_attn.qkv_proj\n",
            "layers.23.mlp\n",
            "layers.23.mlp.gate_up_proj\n",
            "layers.23.mlp.down_proj\n",
            "layers.23.mlp.activation_fn\n",
            "layers.23.input_layernorm\n",
            "layers.23.post_attention_layernorm\n",
            "layers.23.resid_attn_dropout\n",
            "layers.23.resid_mlp_dropout\n",
            "layers.24\n",
            "layers.24.self_attn\n",
            "layers.24.self_attn.o_proj\n",
            "layers.24.self_attn.qkv_proj\n",
            "layers.24.mlp\n",
            "layers.24.mlp.gate_up_proj\n",
            "layers.24.mlp.down_proj\n",
            "layers.24.mlp.activation_fn\n",
            "layers.24.input_layernorm\n",
            "layers.24.post_attention_layernorm\n",
            "layers.24.resid_attn_dropout\n",
            "layers.24.resid_mlp_dropout\n",
            "layers.25\n",
            "layers.25.self_attn\n",
            "layers.25.self_attn.o_proj\n",
            "layers.25.self_attn.qkv_proj\n",
            "layers.25.mlp\n",
            "layers.25.mlp.gate_up_proj\n",
            "layers.25.mlp.down_proj\n",
            "layers.25.mlp.activation_fn\n",
            "layers.25.input_layernorm\n",
            "layers.25.post_attention_layernorm\n",
            "layers.25.resid_attn_dropout\n",
            "layers.25.resid_mlp_dropout\n",
            "layers.26\n",
            "layers.26.self_attn\n",
            "layers.26.self_attn.o_proj\n",
            "layers.26.self_attn.qkv_proj\n",
            "layers.26.mlp\n",
            "layers.26.mlp.gate_up_proj\n",
            "layers.26.mlp.down_proj\n",
            "layers.26.mlp.activation_fn\n",
            "layers.26.input_layernorm\n",
            "layers.26.post_attention_layernorm\n",
            "layers.26.resid_attn_dropout\n",
            "layers.26.resid_mlp_dropout\n",
            "layers.27\n",
            "layers.27.self_attn\n",
            "layers.27.self_attn.o_proj\n",
            "layers.27.self_attn.qkv_proj\n",
            "layers.27.mlp\n",
            "layers.27.mlp.gate_up_proj\n",
            "layers.27.mlp.down_proj\n",
            "layers.27.mlp.activation_fn\n",
            "layers.27.input_layernorm\n",
            "layers.27.post_attention_layernorm\n",
            "layers.27.resid_attn_dropout\n",
            "layers.27.resid_mlp_dropout\n",
            "layers.28\n",
            "layers.28.self_attn\n",
            "layers.28.self_attn.o_proj\n",
            "layers.28.self_attn.qkv_proj\n",
            "layers.28.mlp\n",
            "layers.28.mlp.gate_up_proj\n",
            "layers.28.mlp.down_proj\n",
            "layers.28.mlp.activation_fn\n",
            "layers.28.input_layernorm\n",
            "layers.28.post_attention_layernorm\n",
            "layers.28.resid_attn_dropout\n",
            "layers.28.resid_mlp_dropout\n",
            "layers.29\n",
            "layers.29.self_attn\n",
            "layers.29.self_attn.o_proj\n",
            "layers.29.self_attn.qkv_proj\n",
            "layers.29.mlp\n",
            "layers.29.mlp.gate_up_proj\n",
            "layers.29.mlp.down_proj\n",
            "layers.29.mlp.activation_fn\n",
            "layers.29.input_layernorm\n",
            "layers.29.post_attention_layernorm\n",
            "layers.29.resid_attn_dropout\n",
            "layers.29.resid_mlp_dropout\n",
            "layers.30\n",
            "layers.30.self_attn\n",
            "layers.30.self_attn.o_proj\n",
            "layers.30.self_attn.qkv_proj\n",
            "layers.30.mlp\n",
            "layers.30.mlp.gate_up_proj\n",
            "layers.30.mlp.down_proj\n",
            "layers.30.mlp.activation_fn\n",
            "layers.30.input_layernorm\n",
            "layers.30.post_attention_layernorm\n",
            "layers.30.resid_attn_dropout\n",
            "layers.30.resid_mlp_dropout\n",
            "layers.31\n",
            "layers.31.self_attn\n",
            "layers.31.self_attn.o_proj\n",
            "layers.31.self_attn.qkv_proj\n",
            "layers.31.mlp\n",
            "layers.31.mlp.gate_up_proj\n",
            "layers.31.mlp.down_proj\n",
            "layers.31.mlp.activation_fn\n",
            "layers.31.input_layernorm\n",
            "layers.31.post_attention_layernorm\n",
            "layers.31.resid_attn_dropout\n",
            "layers.31.resid_mlp_dropout\n",
            "layers.32\n",
            "layers.32.self_attn\n",
            "layers.32.self_attn.o_proj\n",
            "layers.32.self_attn.qkv_proj\n",
            "layers.32.mlp\n",
            "layers.32.mlp.gate_up_proj\n",
            "layers.32.mlp.down_proj\n",
            "layers.32.mlp.activation_fn\n",
            "layers.32.input_layernorm\n",
            "layers.32.post_attention_layernorm\n",
            "layers.32.resid_attn_dropout\n",
            "layers.32.resid_mlp_dropout\n",
            "layers.33\n",
            "layers.33.self_attn\n",
            "layers.33.self_attn.o_proj\n",
            "layers.33.self_attn.qkv_proj\n",
            "layers.33.mlp\n",
            "layers.33.mlp.gate_up_proj\n",
            "layers.33.mlp.down_proj\n",
            "layers.33.mlp.activation_fn\n",
            "layers.33.input_layernorm\n",
            "layers.33.post_attention_layernorm\n",
            "layers.33.resid_attn_dropout\n",
            "layers.33.resid_mlp_dropout\n",
            "layers.34\n",
            "layers.34.self_attn\n",
            "layers.34.self_attn.o_proj\n",
            "layers.34.self_attn.qkv_proj\n",
            "layers.34.mlp\n",
            "layers.34.mlp.gate_up_proj\n",
            "layers.34.mlp.down_proj\n",
            "layers.34.mlp.activation_fn\n",
            "layers.34.input_layernorm\n",
            "layers.34.post_attention_layernorm\n",
            "layers.34.resid_attn_dropout\n",
            "layers.34.resid_mlp_dropout\n",
            "layers.35\n",
            "layers.35.self_attn\n",
            "layers.35.self_attn.o_proj\n",
            "layers.35.self_attn.qkv_proj\n",
            "layers.35.mlp\n",
            "layers.35.mlp.gate_up_proj\n",
            "layers.35.mlp.down_proj\n",
            "layers.35.mlp.activation_fn\n",
            "layers.35.input_layernorm\n",
            "layers.35.post_attention_layernorm\n",
            "layers.35.resid_attn_dropout\n",
            "layers.35.resid_mlp_dropout\n",
            "layers.36\n",
            "layers.36.self_attn\n",
            "layers.36.self_attn.o_proj\n",
            "layers.36.self_attn.qkv_proj\n",
            "layers.36.mlp\n",
            "layers.36.mlp.gate_up_proj\n",
            "layers.36.mlp.down_proj\n",
            "layers.36.mlp.activation_fn\n",
            "layers.36.input_layernorm\n",
            "layers.36.post_attention_layernorm\n",
            "layers.36.resid_attn_dropout\n",
            "layers.36.resid_mlp_dropout\n",
            "layers.37\n",
            "layers.37.self_attn\n",
            "layers.37.self_attn.o_proj\n",
            "layers.37.self_attn.qkv_proj\n",
            "layers.37.mlp\n",
            "layers.37.mlp.gate_up_proj\n",
            "layers.37.mlp.down_proj\n",
            "layers.37.mlp.activation_fn\n",
            "layers.37.input_layernorm\n",
            "layers.37.post_attention_layernorm\n",
            "layers.37.resid_attn_dropout\n",
            "layers.37.resid_mlp_dropout\n",
            "layers.38\n",
            "layers.38.self_attn\n",
            "layers.38.self_attn.o_proj\n",
            "layers.38.self_attn.qkv_proj\n",
            "layers.38.mlp\n",
            "layers.38.mlp.gate_up_proj\n",
            "layers.38.mlp.down_proj\n",
            "layers.38.mlp.activation_fn\n",
            "layers.38.input_layernorm\n",
            "layers.38.post_attention_layernorm\n",
            "layers.38.resid_attn_dropout\n",
            "layers.38.resid_mlp_dropout\n",
            "layers.39\n",
            "layers.39.self_attn\n",
            "layers.39.self_attn.o_proj\n",
            "layers.39.self_attn.qkv_proj\n",
            "layers.39.mlp\n",
            "layers.39.mlp.gate_up_proj\n",
            "layers.39.mlp.down_proj\n",
            "layers.39.mlp.activation_fn\n",
            "layers.39.input_layernorm\n",
            "layers.39.post_attention_layernorm\n",
            "layers.39.resid_attn_dropout\n",
            "layers.39.resid_mlp_dropout\n",
            "norm\n",
            "rotary_emb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()"
      ],
      "metadata": {
        "id": "fxyG-nnXIo4E"
      },
      "execution_count": 10,
      "outputs": []
    }
  ]
}